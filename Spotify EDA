{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11938662,"sourceType":"datasetVersion","datasetId":7505821},{"sourceId":11938677,"sourceType":"datasetVersion","datasetId":7505829}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/youssefzeroual/spotify-eda?scriptVersionId=241675436\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA) of My Spotify Listening History**\n\n### ***By Youssef ZEROUAL***\n## **1 Introduction**\n\nThe present analysis draws upon my own spotify listening data downloaded from Spotify's \"Extended Streaming History\" request, consisting of JSON files covering the period from 2018 to 2025. Additionay, the main streaming data was combined with my 'liked' playlist data that I downloaded using Exportify, in order to enrich the main dataset with track features such as duration, energy, da,ceability, addition date, etc.\n\nThe primary objective of this EDA is to **uncover patterns, anomalies, and potential insights** within my extended listening history. The approach involves understanding the data structure and identifying trends, then generating further questions for deeper analysis based on observed patterns. The process includes data loading, cleaning, feature engineering, performing basic statistics, data aggregation, and visualization.\n\n### **1.1 Purpose of the Analysis**\n\nThe analysis aims to address a variety of specific questions and provide insights into different aspects of the listening history. Below is a summary of these objectives:\n\n##### **A. Understanding the Dataset**\nThis section focuses on exploring the structure, quality, and characteristics of the Spotify dataset:\n- **Structure and Features**  \n  - What is the structure of the downloaded Spotify data (e.g., features, missing values, distributions)?  \n  - What is the total number of listening records and features in the dataset?  \n\n- **Data Quality**  \n  - Where are the missing values located in the initial data?  \n  - How does merging with liked songs data affect the dataset dimensions and missing values?  \n  - Which columns are irrelevant for music streaming analysis and should be removed?  \n  - What is the impact of data cleaning steps (e.g., dropping rows with missing timestamps or track names) on the dataset size?  \n\n- **Anomalies and Errors**  \n  - Are there extremely short playbacks that might indicate logging errors?  \n  - Are there instances of implausible playback durations within an hour, suggesting overlapping entries?\n\n \n\n##### **B. Identifying Temporal Listening Trends**\nThis section examines how listening behavior evolves over time:\n- **Yearly Trends**  \n  - How have total listening hours evolved year-over-year?  \n  - Which year was the most active for listening?  \n\n- **Monthly Trends for the most active year**  \n  - How did listening vary month-to-month in the most active year ?  \n  - Which months had the most listening in the most active year?  \n  - Were there seasonal patterns or spikes in the most active year listening?  \n  - How evenly was Spotify used throughout the most active year?  \n\n- **Monthly Trends (All Years)**  \n  - How does listening behavior vary by month when aggregating data from all years?  \n  - Are there consistent seasonal patterns in listening across multiple years?  \n  - How does monthly listening compare when averaged across multiple years?  \n  - How did monthly listening habits change year-over-year from 2018 to 2025?  \n  - Did the same months consistently stand out for listening each year?  \n\n- **Daily and Hourly Patterns**  \n  - How does listening activity distribute across the days of the week?  \n  - Which hours of the day have the peak engagement periods?  \n  - Which hours have the lowest listening frequency?  \n\n- **Sequential Analysis**  \n  - What long-term trends are visible when viewing listening hours sequentially by month (`month_sequential_n`)?  \n  - What short-term fluctuations and patterns are evident when viewing listening hours sequentially by day (`day_sequential_n`)?  \n  - What patterns exist when viewing listening hours sequentially by hour (`hour_sequential_n`)?\n\n\n##### **C. Investigating Song Curation Habits**\nThis section explores how new songs were added to the liked songs library:\n- **Timeline of Additions**  \n  - When were new songs added to the liked songs library?  \n  - Which years saw the most song additions?  \n\n- **Monthly and Yearly Rates**  \n  - What was the rate of new song additions by month for each year?  \n\n- **Genre Analysis for the most active year**  \n  - What genres were most represented in the new songs added in the most active year?  \n\n- **Overall Statistics**  \n  - What are the overall statistics (total, max, min, mean, std) for new songs added per month across all years?  \n\n- **Curation Spikes**  \n  - Are there specific periods (e.g., certain months or years) that show intense curation spikes or declines?\n\n##### **D. Analyzing Genre and Artist Preferences**\nThis section dives into genre and artist preferences based on listening behavior:\n- **Genre Preferences**  \n  - Which music genres have been listened to the most based on total hours played?  \n  - How diverse or focused is the overall music taste?  \n  - How much time was spent listening to the top genres?  \n\n- **Artist Contributions**  \n  - Which artists contributed most to the listening time in the top genre?  \n  - Which specific tracks by the dominant artist in that genre were listened to most?  \n\n- **Artist Rankings**  \n  - Which artists have been listened to the most based on total playback hours?  \n  - Which artists have been played most frequently based on play count?  \n  - How do artists compare in terms of total playback hours vs. play count?\n##### **E. Understanding Song Engagement and Popularity**\nThis section identifies the most popular and frequently played songs:\n- **Most Played Songs**  \n  - Which songs are the most frequently played?  \n  - Which songs have been played across the most unique years?  \n  - Which songs have been played on the most unique days?  \n  - Which songs have appeared in the most unique hourly listening sessions?  \n\n- **Peak Engagement Hours**  \n  - What are the peak hours of the day for the top 3 most engaged songs?\n### **1.2 Dataset Overview** \n- **Source**: Downloaded from [Spotify's \"Extended Streaming History\" data request](https://www.spotify.com/us/account/privacy/). and Exportify website.\n- **Format**: The main streeming dataset is in JSON format (`endsong_*.json`) while the liked playlist is a csv file.\n- **Period**: 2018-2025\n- **Expected Variables**:  \n  - Timestamps, track/artist names, play duration, skipped tracks, etc.  \n\n### **1.3. Approach** \nThe workflow for the exploratory data analysis (EDA) of the Spotify listening history begins by **loading and combining multiple JSON files containing streaming data from 2018 to 2025 into a single dataset**. Initial data inspection involves checking dimensions and identifying missing values, followed by **cleaning steps such as removing irrelevant podcast/audiobook columns** **and dropping rows with missing timestamps or track names**. The dataset is then **merged with liked songs data**, and **features are engineered to extract time-based information, calculate play metrics, and add sequential temporal identifiers**. Further data quality checks include filtering out extremely short playbacks and addressing anomalies like overlapping entries, before proceeding with various analyses on listening patterns by time, artists, genres, and song engagement.","metadata":{}},{"cell_type":"markdown","source":"## **2. Data preparation, inspection and cleaning**\n### **2.1. Importing Required Libraries**\n**Key Packages**:\n- `pandas`: For data manipulation and analysis\n- `numpy`: For numerical operations\n- `seaborn` & `matplotlib`: For data visualization\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:48.015425Z","iopub.execute_input":"2025-05-25T00:08:48.015712Z","iopub.status.idle":"2025-05-25T00:08:48.020491Z","shell.execute_reply.started":"2025-05-25T00:08:48.015694Z","shell.execute_reply":"2025-05-25T00:08:48.019244Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **2.2 Loading and Combining Spotify Data Files**\n\n**Purpose**: Import and merge multiple JSON files containing streaming history into a single DataFrame for comprehensive analysis.\n\n**Files Loaded**:\n- 2018-2020\n- 2020-2022\n- 2022-2023\n- 2023-2024\n- 2024-2025\n\n**Actions Performed**:\n1. Each JSON file loaded separately as a DataFrame\n2. All datasets combined using `pd.concat()`\n\n**Why This Matters**:\n- Creates unified dataset for full historical analysis\n- Enables tracking of listening habits over 7-year period\n- Provides foundation for all subsequent EDA\n  ","metadata":{}},{"cell_type":"code","source":"df_0 = pd.read_json('/kaggle/input/spotify-jsons-2018-2025/anon_Streaming_History_Audio_2018-2020_0.json')\ndf_1 = pd.read_json('/kaggle/input/spotify-jsons-2018-2025/anon_Streaming_History_Audio_2020-2022_1.json')\ndf_2 = pd.read_json('/kaggle/input/spotify-jsons-2018-2025/anon_Streaming_History_Audio_2022-2023_2.json')\ndf_3 = pd.read_json('/kaggle/input/spotify-jsons-2018-2025/anon_Streaming_History_Audio_2023-2024_3.json')\ndf_4 = pd.read_json('/kaggle/input/spotify-jsons-2018-2025/anon_Streaming_History_Audio_2024-2025_4.json')\n\ndf_main = pd.concat([df_0, df_1, df_2, df_3, df_4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:48.038829Z","iopub.execute_input":"2025-05-25T00:08:48.03918Z","iopub.status.idle":"2025-05-25T00:08:48.955927Z","shell.execute_reply.started":"2025-05-25T00:08:48.039151Z","shell.execute_reply":"2025-05-25T00:08:48.955015Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **2.3 Initial Data Inspection**\n#### **2.3.1 Inspecting dataset dimensions**\n\n**Why This Matters**:\n- Gives first indication of dataset size\n- Helps estimate computational requirements\n- Sets expectations for analysis scope\n- Verifies successful concatenation of all files","metadata":{}},{"cell_type":"code","source":"df_main.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:48.957454Z","iopub.execute_input":"2025-05-25T00:08:48.957728Z","iopub.status.idle":"2025-05-25T00:08:48.963728Z","shell.execute_reply.started":"2025-05-25T00:08:48.957699Z","shell.execute_reply":"2025-05-25T00:08:48.962604Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Output Interpretation**:\n- **68,731 rows**: Total recorded listening events (2018-2025)\n- **23 columns**: Available track/stream attributes\n\n**Implications**:\n- Substantial dataset (~69k plays) enables robust trend analysis\n- 23 variables provide multiple dimensions for exploration (timestamps, track details, etc.)\n","metadata":{}},{"cell_type":"markdown","source":"#### **2.3.2 Checking for Missing Values**\n\n**Why This Matters**:\n- Missing data can skew analysis results\n- Helps determine appropriate cleaning strategies\n- Identifies potential data quality issues","metadata":{}},{"cell_type":"code","source":"df_main.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:48.964538Z","iopub.execute_input":"2025-05-25T00:08:48.96483Z","iopub.status.idle":"2025-05-25T00:08:49.026563Z","shell.execute_reply.started":"2025-05-25T00:08:48.964808Z","shell.execute_reply":"2025-05-25T00:08:49.0257Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Key Findings**\n\n- **195 missing entries** in track metadata:\n  - Track names\n  - Artist names  \n  - Album names\n  - Spotify URIs\n- **All other columns complete** (0 missing values)\n\n**Interpretation**:\n✅ **Good Data Quality** for:\n- Timestamps (`ts`)\n- Play duration (`ms_played`)  \n- User behavior metrics (`skipped`, `shuffle`)\n\n⚠️ **Metadata Gaps** (195/68,731 = 0.28%):\n- Likely represents unavailable tracks (e.g., deleted/local files)\n- Small enough to either:\n  - Drop rows (if analysis focuses on track attributes)\n  - Keep and flag (if analyzing broad listening patterns)\n","metadata":{}},{"cell_type":"markdown","source":"### **2.4 Removing Irrelevant Columns**\n\n**Purpose**: Streamline the dataset by dropping unused podcast/audiobook fields.\n\n**Columns Removed**:\n- Podcast-related:  \n  `episode_name`, `episode_show_name`, `spotify_episode_uri`\n- Audiobook-related:  \n  `audiobook_title`, `audiobook_uri`, `audiobook_chapter_uri`, `audiobook_chapter_title`\n- Technical:  \n  `offline_timestamp`\n\n**Reason**:\n- Focuses analysis on **music streaming** only\n- Reduces memory usage\n- Simplifies subsequent data exploration","metadata":{}},{"cell_type":"code","source":"df_main = df_main.drop([\n    'episode_name', 'episode_show_name', 'spotify_episode_uri',\n    'audiobook_title', 'audiobook_uri', 'audiobook_chapter_uri',\n    'audiobook_chapter_title', 'offline_timestamp'\n], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.02907Z","iopub.execute_input":"2025-05-25T00:08:49.029448Z","iopub.status.idle":"2025-05-25T00:08:49.050103Z","shell.execute_reply.started":"2025-05-25T00:08:49.029404Z","shell.execute_reply":"2025-05-25T00:08:49.049049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_main.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.051347Z","iopub.execute_input":"2025-05-25T00:08:49.051672Z","iopub.status.idle":"2025-05-25T00:08:49.099342Z","shell.execute_reply.started":"2025-05-25T00:08:49.051644Z","shell.execute_reply":"2025-05-25T00:08:49.098133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Key Insights**:\n1. **Consistent Pattern**: The same 195 records are missing across all track metadata fields\n2. **Minimal Impact**: Affects only 0.28% of total listening history\n3. **Complete Data**: All behavioral metrics (`skipped`, `shuffle`, etc.) are fully populated\n\n","metadata":{}},{"cell_type":"markdown","source":"### **2.5 Merging Listening History with Liked Songs**\n\n**Purpose**: Combine streaming activity data with liked tracks to analyze listening preferences vs. saved favorites.\n\n**Actions Performed**:\n1. Loaded liked songs data (`liked_songs.csv`)\n2. Merged with main dataset using:\n   - `left_on='spotify_track_uri'` (from listening history)\n   - `right_on='Track URI'` (from liked songs)\n   - `how='outer'` (to preserve all records)\n3. Dropped redundant `'Added By'` column\n4. Displayed first 3 merged rows for verification\n5. Inspected the newly merged dataset: examining column names, column infos,df shape and missing data\n**Key Columns Added**:\n- Liked song metadata (title, artist, album from library)\n- Liked status indicator (will appear as NaN for unliked tracks)\n\n**Merge Implications**:\n- Outer join preserves:\n  - All 68,731 listening records\n  - All liked songs (even those not in recent listening history)\n- Creates unified dataset for preference analysis\n","metadata":{}},{"cell_type":"code","source":"df_liked = pd.read_csv('/kaggle/input/liked-songs/liked_songs.csv')\n\ndf_merged = df_main.merge(df_liked, left_on='spotify_track_uri', right_on='Track URI', how='outer')\ndf_merged=df_merged.drop('Added By', axis=1)\ndf_merged.sample(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.100391Z","iopub.execute_input":"2025-05-25T00:08:49.100668Z","iopub.status.idle":"2025-05-25T00:08:49.350465Z","shell.execute_reply.started":"2025-05-25T00:08:49.100646Z","shell.execute_reply":"2025-05-25T00:08:49.349457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **2.6 Comprehensive Missing Values Analysis After Merge**\n\n**Purpose**: Identify data completeness issues in the merged listening history + liked songs dataset.","metadata":{}},{"cell_type":"code","source":"df_merged.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.351406Z","iopub.execute_input":"2025-05-25T00:08:49.351666Z","iopub.status.idle":"2025-05-25T00:08:49.357985Z","shell.execute_reply.started":"2025-05-25T00:08:49.351646Z","shell.execute_reply":"2025-05-25T00:08:49.356854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged.info()","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.359119Z","iopub.execute_input":"2025-05-25T00:08:49.359439Z","iopub.status.idle":"2025-05-25T00:08:49.495691Z","shell.execute_reply.started":"2025-05-25T00:08:49.359414Z","shell.execute_reply":"2025-05-25T00:08:49.494641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged.isna().sum()","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.496707Z","iopub.execute_input":"2025-05-25T00:08:49.496988Z","iopub.status.idle":"2025-05-25T00:08:49.611426Z","shell.execute_reply.started":"2025-05-25T00:08:49.496955Z","shell.execute_reply":"2025-05-25T00:08:49.61047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Key Findings**\n\n**Listening History Columns**:\n- 145 missing values in core metrics (`ts`, `ms_played`, etc.)\n- 340 missing in original track metadata fields\n\n**Liked Songs Columns**:\n- ~22k missing in basic track info (`Track URI`, `Track Name`, etc.)\n- ~28.8k missing in `Genres`\n- ~22k missing in audio features (danceability, energy, etc.)\n\n### **2.7 Data Quality Assessment**\n\n1.7.1 **Listening Data**:\n   - Minimal missingness (145/68k = 0.2% for behavioral data)\n   - Track metadata gaps slightly increased after merge\n\n1.7.2 **Liked Songs Data**:\n   - Expected large gaps (tracks not in liked songs library)\n   - Audio features missing for unliked tracks\n","metadata":{}},{"cell_type":"markdown","source":"### **2.8 Data Cleaning**\n- **Missing Values Handling**: Dropped NA rows in critical columns:  \n  - `ts` (timestamp) - essential for time-based analysis  \n  - `master_metadata_track_name` (track name) - core entity for analysis  ","metadata":{}},{"cell_type":"code","source":"df_merged=df_merged.dropna(subset=['ts','master_metadata_track_name'])\ndf_merged.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.614819Z","iopub.execute_input":"2025-05-25T00:08:49.615105Z","iopub.status.idle":"2025-05-25T00:08:49.681388Z","shell.execute_reply.started":"2025-05-25T00:08:49.615081Z","shell.execute_reply":"2025-05-25T00:08:49.680354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Key Insights**  \n- **Impact**:  \n  - **68,536 rows × 37 columns** remain \n","metadata":{}},{"cell_type":"markdown","source":"### **2.8 Checking and dropping duplicates in the timestamp column**","metadata":{}},{"cell_type":"code","source":"df_merged=df_merged.drop_duplicates(subset='ts')\ndf_merged.duplicated(subset='ts').sum()","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.682146Z","iopub.execute_input":"2025-05-25T00:08:49.682443Z","iopub.status.idle":"2025-05-25T00:08:49.746563Z","shell.execute_reply.started":"2025-05-25T00:08:49.682423Z","shell.execute_reply":"2025-05-25T00:08:49.745402Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **3. Feature Engineering**\n### **3.1 Mutual Missing Value Filling after merging df_main and df_liked**\n\nFills gaps in paired columns by copying values where one column has data and the other is null. Applied to:\n\n- Track URIs  \n- Track Names  \n- Artist Names  \n- Album Names  ","metadata":{}},{"cell_type":"code","source":"def mutually_fill_missing_values_inplace(df, col1, col2):\n    \"\"\"\n    Fill missing values in two columns mutually where one has data and the other doesn't (in-place).\n    \"\"\"\n    # Fill col2 where col1 has values and col2 is null\n    condition1 = (~df[col1].isnull()) & (df[col2].isnull())\n    df.loc[condition1, col2] = df.loc[condition1, col1]\n    \n    # Fill col1 where col2 has values and col1 is null\n    condition2 = (~df[col2].isnull()) & (df[col1].isnull())\n    df.loc[condition2, col1] = df.loc[condition2, col2]","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.747617Z","iopub.execute_input":"2025-05-25T00:08:49.747873Z","iopub.status.idle":"2025-05-25T00:08:49.754138Z","shell.execute_reply.started":"2025-05-25T00:08:49.747851Z","shell.execute_reply":"2025-05-25T00:08:49.752959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mutually_fill_missing_values_inplace(df_merged, 'Track URI', 'spotify_track_uri')\nmutually_fill_missing_values_inplace(df_merged, 'Track Name', 'master_metadata_track_name')\nmutually_fill_missing_values_inplace(df_merged, 'Artist Name(s)', 'master_metadata_album_artist_name')\nmutually_fill_missing_values_inplace(df_merged, 'Album Name', 'master_metadata_album_album_name')","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.75523Z","iopub.execute_input":"2025-05-25T00:08:49.755554Z","iopub.status.idle":"2025-05-25T00:08:49.899774Z","shell.execute_reply.started":"2025-05-25T00:08:49.755514Z","shell.execute_reply":"2025-05-25T00:08:49.898775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **3.2 Time Data Preprocessing & Feature Engineering**\n\nPerformed the following transformations:\n\n**DateTime Features:**\n- Converted timestamps to datetime objects\n- Extracted date, year, month (name), day, and hour components\n- Created similar features for track addition time\n\n**Play Metrics:**\n- Calculated play duration in minutes and hours\n- Identified non-skipped tracks (≥30s plays)\n- Added track play counts excluding skips\n- Created binary 'liked' flag for saved tracks\n\n**Data Quality:**\n- Handled missing values in temporal fields\n- Standardized duration measurements","metadata":{}},{"cell_type":"code","source":"# Convert the 'ts' column to datetime format\ndf_merged['ts'] = pd.to_datetime(df_merged['ts'])\n\n# Extract the date part from 'ts' and store it in a new 'date' column\ndf_merged['date'] = df_merged['ts'].dt.date\n\n# Convert the 'Added At' column to datetime format\ndf_merged['Added At'] = pd.to_datetime(df_merged['Added At'])\n\n# Extract the year from 'ts' and create a new 'year' column\ndf_merged['year'] = df_merged['ts'].dt.year\n\n# Fill missing year values with 0 and convert to integer type\ndf_merged['year'] = df_merged['year'].fillna(0)\ndf_merged['year'] = df_merged['year'].astype(int)\n\n# Define a dictionary mapping month numbers to month names\nmonths = {\n    1.0: 'January',\n    2.0: 'February',\n    3.0: 'March',\n    4.0: 'April',\n    5.0: 'May',\n    6.0: 'June',\n    7.0: 'July',\n    8.0: 'August',\n    9.0: 'September',\n    10.0: 'October',\n    11.0: 'November',\n    12.0: 'December'\n}\n\n# Extract the month number from 'ts' and map it to month names\ndf_merged['month_n'] = df_merged['ts'].dt.month\ndf_merged['month'] = df_merged['month_n'].map(months)\n\ndf_merged['day'] = df_merged.ts.dt.day\ndf_merged['weekday_n'] = df_merged.ts.dt.weekday\nday_dict = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\ndf_merged['weekday'] = df_merged['weekday_n'].map(day_dict)\n\n\ndf_merged['hour'] = df_merged.ts.dt.hour\n# Extract the year when the track was added\ndf_merged['year_added'] = df_merged['Added At'].dt.year\n\n# Extract the month when the track was added and map it to month names\ndf_merged['month_added'] = df_merged['Added At'].dt.month\ndf_merged['month_added'] = df_merged['month_added'].map(months)\n\n# Calculate total minutes played, rounding to one decimal place\ndf_merged['minutes_played'] = np.round(df_merged['ms_played'] / (1000 * 60), 4)\n\n# Calculate total hours played, rounding to one decimal place\ndf_merged['hours_played'] = np.round(df_merged['ms_played'] / (1000 * 60 * 60), 4)\n\n# Fill missing values in 'year_added' with 0 and convert to integer\ndf_merged['year_added'] = df_merged['year_added'].fillna(0)\ndf_merged['year_added'] = df_merged['year_added'].astype(int)\n\n# Create a condition for tracks that were played for at least 30 seconds (30000 ms)\ncondition = (df_merged['ms_played'] >= 30000)\n\n# Filter non-skipped tracks and group by track URI to count plays\ndf_not_skipped_count = df_merged.loc[condition, :]\ndf_not_skipped_count = df_not_skipped_count.groupby('spotify_track_uri').count().reset_index().iloc[:, :2]\n\n# Rename columns for clarity\ndf_not_skipped_count.columns = ['spotify_track_uri', 'not_skipped_count']\n\n# Merge the count of non-skipped plays back into the main DataFrame\ndf_merged = df_merged.merge(df_not_skipped_count, on='spotify_track_uri', how='left')\n\n# Convert duration from milliseconds to minutes and round to two decimal places\ndf_merged['Duration_minutes'] = np.round(df_merged['Duration (ms)'] / (1000 * 60), 2)\n\n\n\n#adding a 'liked' column to distinguish liked tracks from the others based on the added at column\ncondition = df_merged['Added At'].isna() == False\ndf_merged['liked'] = False\ndf_merged.loc[condition,'liked'] = True\n\n# Display information about the final DataFrame structure\ndf_merged.info()","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:49.900816Z","iopub.execute_input":"2025-05-25T00:08:49.901112Z","iopub.status.idle":"2025-05-25T00:08:50.495619Z","shell.execute_reply.started":"2025-05-25T00:08:49.901089Z","shell.execute_reply":"2025-05-25T00:08:50.494323Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **3.3. Further Temporal Feature Engineering: Adding Sequential Month, Day, and Hour**\n\nThis part of our notebook performs feature engineering on the `df_merged` DataFrame to add sequential month, day, and hour columns. These new columns facilitate easier analysis of the dataset over time.\n\n##### **Key Components**\n\n1. **Month Dictionary**:\n   - `month_dict_inverted`: A dictionary mapping month names to their corresponding numerical values (1-12).\n\n2. **Adding Sequential Month**:\n   - Convert the `month` column to numerical values using the `month_dict_inverted` dictionary.\n   - Fill any missing values with 0 and convert the column to integer type.\n   - Create a `year_month` column by converting the `ts` column to a period of months.\n   - Group by `year` and `month_n` to create a DataFrame (`df_months`) with a sequential month number (`month_sequential_n`).\n   - Merge `df_months` back into `df_merged` to add the `month_sequential_n` column.\n\n3. **Adding Sequential Day**:\n   - Create a `year_day` column by converting the `ts` column to a period of days.\n   - Extract the day from the `ts` column and create a `day` column.\n   - Group by `ts` and `day` to create a DataFrame (`df_days`) with a sequential day number (`day_sequential_n`).\n   - Merge `df_days` back into `df_merged` to add the `day_sequential_n` column.\n\n4. **Adding Sequential Hour**:\n   - Group by `ts` and `hour` to create a DataFrame (`df_hours`) with a sequential hour number (`hour_sequential_n`).\n   - Merge `df_hours` back into `df_merged` to add the `hour_sequential_n` column.\n \n##### **Benefits**\n\n- **Sequential Month**:\n  - Facilitates time-series analysis by providing a continuous sequence of months.\n  - Useful for visualizing trends over months.\n\n- **Sequential Day**:\n  - Provides a continuous sequence of days, useful for daily trend analysis.\n  - Helps in identifying patterns and anomalies on a daily basis.\n\n- **Sequential Hour**:\n  - Provides a continuous sequence of hours, useful for hourly trend analysis.\n  - Helps in identifying peak hours and patterns within a day.\n  ","metadata":{}},{"cell_type":"code","source":"# Dictionary to map month names to their corresponding numerical values (1-12)\nmonth_dict_inverted = {\n    \"January\": 1,\n    \"February\": 2,\n    \"March\": 3,\n    \"April\": 4,\n    \"May\": 5,\n    \"June\": 6,\n    \"July\": 7,\n    \"August\": 8,\n    \"September\": 9,\n    \"October\": 10,\n    \"November\": 11,\n    \"December\": 12\n}\n'''\n# Map the month names to their numerical values using the dictionary\ndf_merged['month_n'] = df_merged['month'].map(month_dict_inverted)\n\n# Fill any missing values with 0 and convert the column to integer type\ndf_merged['month_n'] = df_merged['month_n'].fillna(0).astype(int)\n'''\n# Create a 'year_month' column by converting the 'ts' column to a period of months\ndf_merged['year_month'] = df_merged['ts'].dt.to_period('M')\n\n# Group by 'year' and 'month_n' to create a DataFrame with a sequential month number\ndf_months = df_merged.groupby(['year', 'month_n']).agg({'year_month': 'first'}).reset_index().dropna()\n\n# Rename the 'year_month' column to 'year_month_2' for merging purposes\ndf_months = df_months.rename({'year_month': 'year_month_2'}, axis=1)\n\n# Add a sequential month number column starting from 0\ndf_months['month_sequential_n'] = list(range(0, df_months.shape[0]))\n\n# Drop the 'month_n' and 'year' columns as they are no longer needed\ndf_months = df_months.drop(['month_n', 'year'], axis=1)\n\n# Merge the sequential month numbers back into the original DataFrame\ndf_merged = df_merged.merge(df_months, left_on='year_month', right_on='year_month_2', how='left')\n\n# Drop the 'year_month_2' column as it is no longer needed\ndf_merged = df_merged.drop('year_month_2', axis=1)\n\n# Create a 'year_day' column by converting the 'ts' column to a period of days\ndf_merged['year_day'] = df_merged['ts'].dt.to_period('D')\n\n# Extract the day from the 'ts' column and create a 'day' column\ndf_merged['day'] = df_merged['ts'].dt.day\n\n# Group by 'ts' and 'day' to create a DataFrame with a sequential day number\ndf_days = df_merged.groupby(['ts', 'day']).agg({'year_day': 'first'}).reset_index()\n\n# Rename columns for merging purposes\ndf_days = df_days.rename({'year_day': 'year_day_2', 'day': 'day_2', 'ts': 'ts_2'}, axis=1)\n\n# Drop duplicates based on 'year_day_2' and reset the index\ndf_days = df_days.drop_duplicates(subset='year_day_2').reset_index(drop=True)\n\n# Add a sequential day number column starting from 0\ndf_days['day_sequential_n'] = list(range(0, df_days.shape[0]))\n\n# Merge the sequential day numbers back into the original DataFrame\ndf_merged = df_merged.merge(df_days, left_on='year_day', right_on='year_day_2', how='left')\n\n# Drop the 'year_day_2', 'day_2', and 'ts_2' columns as they are no longer needed\ndf_merged = df_merged.drop(['year_day_2', 'day_2', 'ts_2'], axis=1)\n\n# Create a 'year_hour' column by converting the 'ts' column to a period of hours\ndf_merged['year_hour'] = df_merged['ts'].dt.to_period('H')\n\n# Extract the hour from the 'ts' column and create an 'hour' column\ndf_merged['hour'] = df_merged['ts'].dt.hour\n\n# Group by 'ts' and 'hour' to create a DataFrame with a sequential hour number\ndf_hours = df_merged.groupby(['ts', 'hour']).agg({'year_hour': 'first'}).reset_index()\n\n# Rename columns for merging purposes\ndf_hours = df_hours.rename({'year_hour': 'year_hour_2', 'hour': 'hour_2', 'ts': 'ts_2'}, axis=1)\n\n# Drop duplicates based on 'year_hour_2'\ndf_hours = df_hours.drop_duplicates(subset='year_hour_2')\n\n# Add a sequential hour number column starting from 0\ndf_hours['hour_sequential_n'] = list(range(0, df_hours.shape[0]))\n\n# Merge the sequential hour numbers back into the original DataFrame\ndf_merged = df_merged.merge(df_hours, left_on='year_hour', right_on='year_hour_2', how='left')\n\n# Drop the 'year_hour_2', 'hour_2', and 'ts_2' columns as they are no longer needed\ndf_merged = df_merged.drop(['year_hour_2', 'hour_2', 'ts_2'], axis=1)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:50.496801Z","iopub.execute_input":"2025-05-25T00:08:50.497085Z","iopub.status.idle":"2025-05-25T00:08:50.846321Z","shell.execute_reply.started":"2025-05-25T00:08:50.497062Z","shell.execute_reply":"2025-05-25T00:08:50.845369Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **4. Data Integrity and validation**\n\n### **4.1 Cheking the number of very short playbacks for possible logging errors:**\n- Eextremely short while not flagged as 'skipped'","metadata":{}},{"cell_type":"code","source":"condition =  (df_merged.ms_played<30_000) & (df_merged.skipped == False)\ndf_merged[condition]['ms_played'].describe()","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:50.847551Z","iopub.execute_input":"2025-05-25T00:08:50.847835Z","iopub.status.idle":"2025-05-25T00:08:50.878746Z","shell.execute_reply.started":"2025-05-25T00:08:50.84781Z","shell.execute_reply":"2025-05-25T00:08:50.877579Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Data Quality Filtering\n\nIdentified 15725 playback records (<5% of total) with duration under 30 seconds. These likely represent:\n\n- Accidental plays\n- Data logging errors\nMost of these values are between 1 and 8 seconds.\n**Action Taken:**  \nFiltered dataset to only include plays ≥30s while not flagged as 'skipped' to ensure:\n- More accurate play counts\n- Reliable listening statistics\n- Better representation of intentional listening\n","metadata":{}},{"cell_type":"code","source":"# keep only records that have more than 30 minutes playback\n\ncondition = ~((df_merged.ms_played<30_000) & (df_merged.skipped == False))\ndf_merged = df_merged[condition]\ndf_merged[condition].shape","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:50.879868Z","iopub.execute_input":"2025-05-25T00:08:50.880227Z","iopub.status.idle":"2025-05-25T00:08:50.955364Z","shell.execute_reply.started":"2025-05-25T00:08:50.880201Z","shell.execute_reply":"2025-05-25T00:08:50.954266Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **4.2 Timestaps vs song end time consistency check**\n**Check:** Ensured total playback time per hour does not exceed 60 minutes (physical limit).  \n\n**Method:**  \n- Grouped records by *year, month, day, hour*  \n- Summed `hours_played` per hour  \n- Flagged top 30 entries for manual review  \n\n**Purpose:**  \n- Detect potential logging errors (e.g., overlapping streams)  \n- Validate dataset consistency for time-based analysis  \n","metadata":{}},{"cell_type":"code","source":"#check data integrity by grouping by hour and check if total playback doesnt exceed 1 hour\noverlapped_hours = df_merged.groupby(['year','month','day','hour']).agg(hours_played=('hours_played','sum'),ts=('ts','first'))\\\n.sort_values('hours_played',ascending=False).head(105).reset_index()\ncondition = overlapped_hours['hours_played']>1\noverlapped_hours = overlapped_hours[condition]\noverlapped_hours","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:50.956197Z","iopub.execute_input":"2025-05-25T00:08:50.956465Z","iopub.status.idle":"2025-05-25T00:08:50.991892Z","shell.execute_reply.started":"2025-05-25T00:08:50.956444Z","shell.execute_reply":"2025-05-25T00:08:50.990826Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Data Anomaly confirmed: Implausible Playback Duration**\n**Issue:**  \nIdentified **104 instances** where hourly playback exceeds 1 hour (max: **3.78h**), suggesting the presence of overlapping entries. \n","metadata":{}},{"cell_type":"markdown","source":"#### **4.2.1 Investigating Playback Anomalies**\nExamining records for 2025-04-16 09:00:","metadata":{}},{"cell_type":"code","source":"condition = (df_merged['year'] == 2025) &(df_merged['month'] =='April') &(df_merged['day'] == 16) &(df_merged['hour'] == 9)  \ndf_merged[condition].sort_values('ts').head(3)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:50.992879Z","iopub.execute_input":"2025-05-25T00:08:50.993125Z","iopub.status.idle":"2025-05-25T00:08:51.024226Z","shell.execute_reply.started":"2025-05-25T00:08:50.993105Z","shell.execute_reply":"2025-05-25T00:08:51.023193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Overlapping timestamps confirmed:**\nThe song Midnight Blues began at 09:00:52 and has an ms_played value of 389,273 (~6.48 minutes), meaning playback should end around 09:07:00. However, the next song starts at 09:04:22, creating an overlap.\n\nThis inconsistency appears to be the primary cause of inflated playback time. To resolve this, we will use a double approache that consists of two phases: **1. fix timesamps themselves without any deleting** and **2. delete the remaining overlapped rows**, ensuring the playback data remains accurate and free from logging errors. We've made this choice because simply deleting overlapping rows resulted in a huge data loss (from 65311-44312 into 23721-17032), on the other hand fixing only timestamps didnt seem to make any changes. \n\n---","metadata":{}},{"cell_type":"markdown","source":"#### **4.2.2 Adressing the overlapping anomaly**\n\n- Adressing the playback time issue by detecting overlapping songs i.e when end time of song A overlaps with start time of song B because this is the main cause of hourly playback being more than 1 hour for some records.\n- After testing, the only way that works is combining the two approaches in a loop\n- We use a double approache that consists of two phases: 1. fix timesamps themselves without any deleting and 2. delete the remaining overlapped rows\n- The whole thing needed to be done for 5 times to have no more overlapsthis insures dealing with the logging errors with a minimal number of deleted rows","metadata":{}},{"cell_type":"code","source":"#phase 1\n# Calculate end time for each track\n\nfor i in range(4):\n    df_merged[\"end_time\"] = df_merged[\"ts\"] + pd.to_timedelta(df_merged[\"ms_played\"], unit=\"ms\")\n    \n    # Sort by timestamp\n    df_merged = df_merged.sort_values(\"ts\")\n    \n    # Calculate the overlap between current track and previous track's end time\n    df_merged[\"overlap_with_previous\"] = df_merged[\"ts\"] - df_merged[\"end_time\"].shift(1)\n    \n    # Only adjust tracks that start before the previous track ended (negative overlap)\n    df_merged[\"needs_adjustment\"] = df_merged[\"overlap_with_previous\"] < pd.Timedelta(0)\n    \n    # For tracks needing adjustment, shift their start time to the previous track's end time\n    df_merged[\"adjusted_ts\"] = df_merged[\"ts\"]\n    df_merged.loc[df_merged[\"needs_adjustment\"], \"adjusted_ts\"] = df_merged[\"end_time\"].shift(1)\n        \n    # Update the original timestamp column (or keep both if I want to compare)\n    df_merged[\"ts\"] = df_merged[\"adjusted_ts\"]\n        \n    # Recalculate end_time with adjusted timestamps\n    df_merged[\"end_time\"] = df_merged[\"ts\"] + pd.to_timedelta(df_merged[\"ms_played\"], unit=\"ms\")\n    \n    # Verify no overlaps remain\n    df_merged[\"overlap\"] = df_merged[\"ts\"] < df_merged[\"end_time\"].shift(1)\n    print(f\"Remaining overlaps: {df_merged['overlap'].sum()}\")\n \n \n    #phase 2\n    df_merged[\"end_time\"] = df_merged[\"ts\"] + pd.to_timedelta(df_merged[\"ms_played\"], unit=\"ms\")\n    \n    # Sort by timestamp\n    df_merged = df_merged.sort_values(\"ts\")\n    \n    # Flag overlaps\n    df_merged[\"overlap\"] = df_merged[\"ts\"] < df_merged[\"end_time\"].shift(1)\n    \n    # Keep only non-overlapping entries\n    df_merged = df_merged[~df_merged[\"overlap\"]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.025653Z","iopub.execute_input":"2025-05-25T00:08:51.025988Z","iopub.status.idle":"2025-05-25T00:08:51.597086Z","shell.execute_reply.started":"2025-05-25T00:08:51.025962Z","shell.execute_reply":"2025-05-25T00:08:51.59574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":" df_merged.shape","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.59826Z","iopub.execute_input":"2025-05-25T00:08:51.598643Z","iopub.status.idle":"2025-05-25T00:08:51.605214Z","shell.execute_reply.started":"2025-05-25T00:08:51.598612Z","shell.execute_reply":"2025-05-25T00:08:51.604283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **5. Functions for exploratory data analysis:**\nThese functions have been written while performing the analysis but I have groupped them here to make the notebook more readable","metadata":{}},{"cell_type":"markdown","source":"### **5.1 Get top tracks by hours played for a specific artist.**\n    \n    Parameters:\n    - df: DataFrame containing the streaming data\n    - artist_name: Name of the artist to filter by\n    - top_n: Number of top tracks to return (default: 10)\n    \n    Returns:\n    - DataFrame with columns: track_name, hours_played, year_added","metadata":{}},{"cell_type":"code","source":"def get_top_tracks_by_artist(df, artist_name, top_n=10):\n  \n    condition = (df['master_metadata_album_artist_name'].str.contains(artist_name, case=False) == True)\n    df_artist = df.loc[condition, :]\n    \n    tracks_by_hours = (df_artist.groupby(['master_metadata_track_name','year_added','not_skipped_count'])\n                       .sum(numeric_only=True)\n                       .reset_index()\n                       .loc[:, ['master_metadata_track_name', 'minutes_played','hours_played','year_added','not_skipped_count']]\n                       .sort_values('minutes_played', ascending=False))\n    \n    top_tracks = tracks_by_hours.head(top_n).reset_index(drop=True)\n    top_tracks['year_added']=top_tracks['year_added'].apply(lambda x:'Unavailable' if x == 0 else x)\n    top_tracks=top_tracks.groupby(['master_metadata_track_name']).agg({'minutes_played':'sum','hours_played':'sum','not_skipped_count':'sum','year_added':'first'}).reset_index().sort_values('hours_played',ascending=False)\n    return top_tracks","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.605926Z","iopub.execute_input":"2025-05-25T00:08:51.606262Z","iopub.status.idle":"2025-05-25T00:08:51.626715Z","shell.execute_reply.started":"2025-05-25T00:08:51.606237Z","shell.execute_reply":"2025-05-25T00:08:51.625632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.2 Get top tracks by playtime with artist and year information.**\n\n\n\n**Parameters:**\n- `df`: Input DataFrame with streaming history\n- `track_col`: Column name for track titles (default: 'master_metadata_track_name')\n- `artist_col`: Column name for artist names (default: 'master_metadata_album_artist_name')\n- `time_col`: Column name for playtime in hours (default: 'hours_played')\n- `year_col`: Column name for year added (default: 'year_added')\n- `n`: Number of top tracks to return (default: 10)\n\n**Returns:**\nDataFrame with columns:\n- Track Name\n- Artist\n- Year Added\n- Total played time in hours\n- not_skipped_count\n- Duration_minutes\n\n**Raises:**\n- `ValueError` if `year_col` is not found in DataFrame","metadata":{}},{"cell_type":"code","source":"def get_top_tracks_with_artists_and_year(df, \n                                       track_col='master_metadata_track_name',\n                                       artist_col='master_metadata_album_artist_name',\n                                       time_col='hours_played',\n                                       year_col='year_added',\n                                       n=10):\n   \n   \n    # First check if year column exists\n    if year_col not in df.columns:\n        raise ValueError(f\"Column '{year_col}' not found in DataFrame. Available columns: {list(df.columns)}\")\n    \n    # Ensure we don't have nulls in key columns\n    df = df.dropna(subset=[track_col, artist_col, year_col, time_col])\n    \n    top_tracks = (\n        df.groupby([track_col, artist_col, year_col,'not_skipped_count','Duration_minutes'], dropna=False)\n        [time_col].sum()\n        .sort_values(ascending=False)\n        .reset_index()\n        .rename(columns={\n            track_col: 'Track Name',\n            artist_col: 'Artist',\n            year_col: 'Year Added',\n            time_col: 'Total played time in hours',\n        })\n        .head(n)\n    )\n    top_tracks.sort_values('Total played time in hours',ascending=False)\n    return top_tracks[['Track Name', 'Artist', 'Year Added', 'Total played time in hours','not_skipped_count','Duration_minutes']]","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.627745Z","iopub.execute_input":"2025-05-25T00:08:51.628009Z","iopub.status.idle":"2025-05-25T00:08:51.654148Z","shell.execute_reply.started":"2025-05-25T00:08:51.627988Z","shell.execute_reply":"2025-05-25T00:08:51.653353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.3 Create Spotify-style bar plots (vertical or horizontal) with value labels.**\n    \n    Parameters:\n    -----------\n    df : DataFrame\n        Input data containing the values to plot\n    x : str\n        Column name for x-axis values (or y-axis if inverted)\n    y : str \n        Column name for y-axis values (or x-axis if inverted)\n    x_label : str\n        Label for x-axis\n    y_label : str\n        Label for y-axis  \n    title : str\n        Plot title\n    inverted : bool, optional (default=False)\n        If True, creates horizontal bar chart instead of vertical\n     ","metadata":{}},{"cell_type":"code","source":"def plot_(df, x, y, x_label, y_label, title, inverted=False):\n    plt.figure(figsize=default_figsize)\n    palette = sns.light_palette(\"#1DB954\", n_colors=df.shape[0], reverse=True)\n    \n    if inverted:\n        ax = sns.barplot(data=df, x=y, y=x, hue=x, orient='h', palette=palette, errorbar=None)\n        for p in ax.patches:\n            width = p.get_width()\n            if not np.isnan(width):\n                label = f'{int(width)}' if width == int(width) else f'{width:.1f}'\n                ax.annotate(label, (width, p.get_y() + p.get_height()/2), \n                           ha='left' if width >= 0 else 'right', va='center',\n                           xytext=(5, 0), textcoords='offset points', fontsize=10)\n        plt.grid(axis='x', linestyle='--', alpha=0.7)\n    else:\n        ax = sns.barplot(data=df, x=x, y=y, hue=x, palette=palette, errorbar=None)\n        for p in ax.patches:\n            height = p.get_height()\n            if not np.isnan(height):\n                label = f'{int(height)}' if height == int(height) else f'{height:.1f}'\n                ax.annotate(label, (p.get_x() + p.get_width()/2, height),\n                           ha='center', va='bottom' if height >= 0 else 'top',\n                           xytext=(0, 5), textcoords='offset points', fontsize=10)\n        plt.grid(axis='y', linestyle='--', alpha=0.7)\n        plt.xticks(rotation=0)\n    \n    ax.legend_.remove()\n    plt.style.use('dark_background')\n    plt.title(title, fontsize=16, pad=20, color='white', fontweight='bold')\n    plt.xlabel(x_label, fontsize=14 if inverted else 12, color='#b3b3b3')\n    plt.ylabel(y_label, fontsize=14 if inverted else 12, color='#b3b3b3')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.655246Z","iopub.execute_input":"2025-05-25T00:08:51.65559Z","iopub.status.idle":"2025-05-25T00:08:51.68305Z","shell.execute_reply.started":"2025-05-25T00:08:51.65556Z","shell.execute_reply":"2025-05-25T00:08:51.68221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.4 Calculate the sum of a metric (criteria2) grouped by a category (criteria1)**\n   \n    \n    Parameters:\n    -----------\n    df : DataFrame\n        Spotify listening history data\n    criteria1 : str\n        Column name to group by (e.g., 'artist', 'track')\n    criteria2 : str \n        Column name to sum (e.g., 'ms_played', 'hours_played')\n        \n    Returns:\n    --------\n    DataFrame with two columns: the grouping column and summed values,\n    filtered to exclude zeros and short plays.\n    ","metadata":{}},{"cell_type":"code","source":"def sum_by(df, criteria1, criteria2):\n  \n    \n   \n    return (df.loc[:, :]\n            .groupby(criteria1)\n            .sum(numeric_only=True)[criteria2]  # Sum only the specified column\n            .reset_index()\n            .loc[:, [criteria1, criteria2]]  # Keep only relevant columns\n            .reset_index(drop=True))  # Clean index","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.684058Z","iopub.execute_input":"2025-05-25T00:08:51.684675Z","iopub.status.idle":"2025-05-25T00:08:51.709361Z","shell.execute_reply.started":"2025-05-25T00:08:51.684643Z","shell.execute_reply":"2025-05-25T00:08:51.708385Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.5 Counts occurrences of a metric (criteria2) grouped by a category (criteria1)**\n     \n    Returns results sorted by count in descending order.\n    \n    Parameters:\n \n    df : DataFrame\n        Spotify listening history data\n    criteria1 : str\n        Column name to group by (e.g., 'artist', 'track')\n    criteria2 : str \n        Column name to count (typically same as criteria1 for play counts)\n        \n    Returns:\n    \n    DataFrame with two columns: the grouping column and counts,\n    filtered to exclude zeros and short plays, sorted by count.\n  ","metadata":{}},{"cell_type":"code","source":"def count_by(df, criteria1, criteria2):\n  \n   \n    \n    return (df.loc[:, :]\n            .groupby(criteria1)\n            .count()[[criteria2]]  # Count occurrences\n            .reset_index()\n            .loc[:, [criteria1, criteria2]]  # Keep only relevant columns\n            .sort_values(criteria2, ascending=False)  # Sort by count descending\n            .reset_index(drop=True))  # Clean index","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.710328Z","iopub.execute_input":"2025-05-25T00:08:51.710618Z","iopub.status.idle":"2025-05-25T00:08:51.735266Z","shell.execute_reply.started":"2025-05-25T00:08:51.710595Z","shell.execute_reply":"2025-05-25T00:08:51.734375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.6 Sort a DataFrame chronologically by month names in a specified column.**\n    \n    - Creates a temporary numeric month column, sorts by it, and maintains the original month names.\n    Useful for ensuring proper month ordering in analyses and visualizations.\n\n- Parameters:\n    - df : pandas.DataFrame\n        The DataFrame containing month names to be sorted\n    - month_col : str\n        Name of the column containing month names (e.g., \"January\", \"February\", etc.)\n- Returns:\n\n    - pandas.DataFrame\n        The input DataFrame sorted in chronological month order (January to December)\n","metadata":{}},{"cell_type":"code","source":"def get_genre_artists(genre,df=df_merged):\n    condition = (df['Genres'].str.contains(genre,case=False,regex=True)==True)\n    df_genre_count = df.loc[condition,:].groupby('master_metadata_album_artist_name').count().reset_index().iloc[:,:2].rename({'ts':'count'},axis=1).sort_values('count',ascending=False)\n    df_genre_sum = df.loc[condition,:].groupby('master_metadata_album_artist_name').sum(numeric_only=True).reset_index().loc[:,['master_metadata_album_artist_name','minutes_played']].rename({'minutes_played':'Total playback time (minutes)'},axis=1).sort_values('Total playback time (minutes)',ascending=False)\n    return df_genre_count,df_genre_sum","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.736252Z","iopub.execute_input":"2025-05-25T00:08:51.736583Z","iopub.status.idle":"2025-05-25T00:08:51.770087Z","shell.execute_reply.started":"2025-05-25T00:08:51.736554Z","shell.execute_reply":"2025-05-25T00:08:51.769025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sort_df_months(df, month_col):\n  \n    # Mapping dictionary to convert month names to numerical values\n    month_name_to_num = {\n        \"January\": 1,\n        \"February\": 2,\n        \"March\": 3,\n        \"April\": 4,\n        \"May\": 5,\n        \"June\": 6,\n        \"July\": 7,\n        \"August\": 8,\n        \"September\": 9,\n        \"October\": 10,\n        \"November\": 11,\n        \"December\": 12\n    }\n    \n    # Create temporary numerical month column for sorting\n    df['month_added_n'] = df[month_col].map(month_name_to_num)\n    \n    # Sort by numerical month while preserving original data\n    sorted_df = df.sort_values('month_added_n')\n    \n    # Optional: Drop the temporary numerical column if desired\n    # sorted_df = sorted_df.drop(columns=['month_added_n'])\n    \n    return sorted_df","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.776152Z","iopub.execute_input":"2025-05-25T00:08:51.776502Z","iopub.status.idle":"2025-05-25T00:08:51.793556Z","shell.execute_reply.started":"2025-05-25T00:08:51.776478Z","shell.execute_reply":"2025-05-25T00:08:51.792328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.7 Get the artists of a specefic genre:**\nreturns two dfs: one that sorts artists by listennings and one by playback time","metadata":{}},{"cell_type":"code","source":"def get_genre_artists(genre,df=df_merged):\n    condition = (df['Genres'].str.contains(genre,case=False,regex=True)==True)\n    df_genre_count = df.loc[condition,:].groupby('master_metadata_album_artist_name').count().reset_index().iloc[:,:2].rename({'ts':'count'},axis=1).sort_values('count',ascending=False)\n    df_genre_sum = df.loc[condition,:].groupby('master_metadata_album_artist_name').sum(numeric_only=True).reset_index().loc[:,['master_metadata_album_artist_name','minutes_played']].rename({'minutes_played':'Total playback time (minutes)'},axis=1).sort_values('Total playback time (minutes)',ascending=False)\n    return df_genre_count,df_genre_sum","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.794585Z","iopub.execute_input":"2025-05-25T00:08:51.794826Z","iopub.status.idle":"2025-05-25T00:08:51.823116Z","shell.execute_reply.started":"2025-05-25T00:08:51.794806Z","shell.execute_reply":"2025-05-25T00:08:51.822135Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **5.8 Plot a set of months with a unique month number for the whole dataset for the new song adding statistics**","metadata":{}},{"cell_type":"code","source":"def plot_(df, x, y, x_label, y_label, title, inverted=False):\n    plt.figure(figsize=default_figsize)\n    palette = sns.light_palette(\"#1DB954\", n_colors=len(df), reverse=True)\n    \n    kwargs = {\n        'data': df,\n        'palette': palette,\n        'errorbar': None,\n        'linewidth': 0,   \n        'width':3     \n    }\n    \n    if inverted:\n        ax = sns.barplot(x=y, y=x, hue=x, orient='h', **kwargs)\n        for p in ax.patches:\n            if not np.isnan(w := p.get_width()):\n                ax.annotate(f'{w:.0f}' if w == int(w) else f'{w:.1f}',\n                           (w, p.get_y() + p.get_height()/2),\n                           ha='left' if w >= 0 else 'right', va='center',\n                           xytext=(5, 0), textcoords='offset points')\n        plt.grid(axis='x', ls='--', alpha=0.3)\n    else:\n        ax = sns.barplot(x=x, y=y, hue=x, **kwargs)\n        for p in ax.patches:\n            if not np.isnan(h := p.get_height()):\n                ax.annotate(f'{h:.0f}' if h == int(h) else f'{h:.1f}',\n                           (p.get_x() + p.get_width()/2, h),\n                           ha='center', va='bottom' if h >= 0 else 'top',\n                           xytext=(0, 5), textcoords='offset points')\n        plt.grid(axis='y', ls='--', alpha=0.3)\n        plt.xticks(rotation=0)\n    \n    ax.legend_.remove()\n    plt.style.use('dark_background')\n    plt.title(title, fontsize=16, pad=20, color='white', weight='bold')\n    plt.xlabel(x_label, fontsize=14 if inverted else 12, color='#b3b3b3')\n    plt.ylabel(y_label, fontsize=14 if inverted else 12, color='#b3b3b3')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.824228Z","iopub.execute_input":"2025-05-25T00:08:51.824786Z","iopub.status.idle":"2025-05-25T00:08:51.850156Z","shell.execute_reply.started":"2025-05-25T00:08:51.824752Z","shell.execute_reply":"2025-05-25T00:08:51.848815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **6 Exploratory Data Analysis**\n### **6.1 Time series analysis**\n#### **6.1.1 Total Hours Listened Per Year**\n\nThis analysis aggregates and sorts the total hours listened per year based on my Spotify data. It helps us understand which years had the most listening activity.\n","metadata":{}},{"cell_type":"code","source":"hours_by_year = sum_by(df_merged, 'year', 'hours_played')\nhours_by_year.sort_values('hours_played',ascending=False).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.85131Z","iopub.execute_input":"2025-05-25T00:08:51.851588Z","iopub.status.idle":"2025-05-25T00:08:51.893148Z","shell.execute_reply.started":"2025-05-25T00:08:51.851565Z","shell.execute_reply":"2025-05-25T00:08:51.892329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set default figure size for the plot (width, height in inches)\ndefault_figsize = (6, 4)  # Smaller than usual for a clean year-by-year view\n\n# Generate the visualization using our plot_() function\nplot_(\n    df=hours_by_year,          # Processed data with years and hours\n    x='year',                  # Column for x-axis (years)\n    y='hours_played',          # Column for y-axis (total hours)\n    x_label='Year',            # Proper x-axis label (more readable than 'Genres')\n    y_label='Total Hours',     # y-axis label\n    title=\"Annual Spotify Listening Hours\",  # More precise title\n    inverted=False             # Standard vertical bar chart\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:51.894118Z","iopub.execute_input":"2025-05-25T00:08:51.894436Z","iopub.status.idle":"2025-05-25T00:08:52.25848Z","shell.execute_reply.started":"2025-05-25T00:08:51.894412Z","shell.execute_reply":"2025-05-25T00:08:52.25736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 📊 **Insights: Total Hours Listened Per Year**\n\nThis analysis reveals how my Spotify listening habits have evolved over time by aggregating the total hours listened each year. Here are the key takeaways:\n\n\n##### **🔝 Top Listening Years**\n- **2020** was my **most active year** for listening, with a total of **368.7 hours** (~15.4 days). This could be attributed to more time spent at home during global events, leading to increased music streaming.\n- **2022 (331.3 hours)** and **2024 (307.9 hours)** follow closely, indicating consistently high engagement in recent years.\n\n\n##### 📉 **Decline in Listening Activity**\n- After 2020, there’s a general decline in total listening time, with **2021** being the lowest point in the early 2020s at **183.9 hours**.\n- The most significant drop appears between **2024 and 2025**, where listening time almost halves to **91.5 hours** — potentially signaling a change in lifestyle, preferences, or data availability.\n\n##### 📅 **Early Years**\n- **2018** has only **0.6 hours** of playback — likely due to incomplete data or minimal usage at the start of the tracking period.\n- By **2019**, listening time jumped significantly to **205.3 hours**, showing early growth in music consumption.\n\n\n##### 🧠 **Observations & Possible Explanations:**\n- **Peak in 2020:** Could align with increased居家时间 (time at home) during that year, prompting more music streaming.\n- **High 2024 Listening:** Might suggest renewed interest in music, new listening habits, or possibly offline activity syncing later.\n- **Sharp Drop in 2025:** Could be due to reduced music usage, busier lifestyle, or possibly incomplete data capture for that year.\n---","metadata":{}},{"cell_type":"markdown","source":"#### **6.1.2 📅 Deep Dive into 2020: Monthly Spotify Listening**\n\nThis section zooms in on the year **2020**, which was previously identified as the year with the **highest total listening time** (~322 hours).\n\n##### 🔧 **What This Code Does:**\n1. ✅ **Filters** the dataset to include only entries from **2020**.\n2. 📈 **Aggregates** total Spotify listening time by **month**, using the `sum_by` function.\n3. 🗓️ **Sorts** the months in chronological order (from **January to December**) using a custom sorting function (`sort_df_months`), ensuring correct time-based analysis.\n4. 🧹 **Cleans up** the output by removing temporary sorting columns and sorts the final table by **listening duration**, from highest to lowest.\n\n##### 🎯 **Purpose:**\nTo understand **how My Spotify listening varied month-to-month in 2020**, identifying:\n- Which months had the **most listening**\n- Whether there were any **seasonal patterns** or spikes\n- How evenly (or unevenly) I used Spotify throughout the year\n","metadata":{}},{"cell_type":"code","source":"# Filter data for only the year 2020\ncondition = df_merged['year'] == 2020\n\n# Calculate total hours played per month for 2020\nhours_by_year = sum_by(\n    df=df_merged[condition],  # Filtered DataFrame\n    criteria1='month',        # Group by month\n    criteria2='hours_played'  # Sum hours played\n)\n\n# Sort months chronologically (January to December)\nhours_by_year = sort_df_months(\n    df=hours_by_year,\n    month_col='month'  # Column containing month names\n).reset_index(drop=True)\n\nhours_by_year.drop('month_added_n',axis=1).sort_values('hours_played',ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:52.259417Z","iopub.execute_input":"2025-05-25T00:08:52.259657Z","iopub.status.idle":"2025-05-25T00:08:52.289911Z","shell.execute_reply.started":"2025-05-25T00:08:52.259638Z","shell.execute_reply":"2025-05-25T00:08:52.288947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize = (13, 4)\n# Generate the visualization with Spotify-style formatting\nplot_(\n    df=hours_by_year,\n    x='month',  # Months on x-axis\n    y='hours_played',  # Hours played on y-axis\n    x_label='Month',  # More accurate than 'Genres'\n    y_label='Total Hours',\n    title=\"Monthly Spotify Listening Hours (2020)\",  # Clearer title\n    inverted=False  # Vertical bar chart\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:52.290943Z","iopub.execute_input":"2025-05-25T00:08:52.291282Z","iopub.status.idle":"2025-05-25T00:08:52.837481Z","shell.execute_reply.started":"2025-05-25T00:08:52.291251Z","shell.execute_reply":"2025-05-25T00:08:52.836353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔍 **Deep Dive into 2020: Monthly Spotify Listening**\n\nThe year **2020** stood out as my most active listening year overall — with **~ 3 68.7 hours (~15.4 days)** of music streamed. Breaking it down month-by-month reveals fascinating patterns about how and when I used Spotify the most.\n\n\n##### 🔝 **Top Listening Months in 2020**\n\n- **July 2020** was by far the highest, with nearly **67 hours** of listening — over **twice** the average monthly total for the year.\n- The top **five months** (July to December) account for more than **80%** of all listening time in 2020.\n- There's a clear **second-half-of-the-year dominance**, suggesting a significant increase in usage starting around mid-year.\n\n\n##### 📉 **Lowest Listening Months**\n\n- **April (2.2 hrs)** and **May (3.9 hrs)** were the least active months — together accounting for less than **2%** of the annual total.\n- This could suggest:\n  - Technical issues or missing data\n  - A period of reduced Spotify usage\n  - A shift toward other media formats (e.g., podcasts, YouTube)\n  - Changes in lifestyle during early lockdowns\n\n\n##### 📊 **Seasonal Trends & Patterns**\n\nThere’s a noticeable **spike in late summer and fall**, peaking in **July**, then remaining high through **December**:\n\n- **July–September**: High listening during warm weather, possibly due to outdoor activities, road trips, or more leisure time.\n- **November–December**: Holiday season and indoor time likely contributed to sustained high usage.\n\nThis pattern suggests that my Spotify use in 2020 may have been influenced by **seasonal changes**, **lifestyle shifts**, and possibly **global events** like lockdowns and remote work.\n\n\n##### 🧠 **Observations & Hypotheses**\n\n- **Post-April Surge**: After a very low point in April, usage begins rising sharply starting in May and peaks in July — potentially aligning with emotional or situational shifts during the pandemic.\n- **Year-End Momentum**: High listening in November and December indicates increased reliance on music during the holiday season or as a coping mechanism at the end of a difficult year.\n- **Data Gaps?**: Very low listening in April and May might also hint at incomplete data capture, especially if I recall being more active during those months.\n","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"#### **6.1.3 📅Examining Monthly Playback Trends Across All Years**\n\nThis section explores how **Spotify listening behavior varies by month**, aggregating data from **all available years**. The goal is to identify any **seasonal patterns**, such as months with consistently high or low listening activity.\n\n##### 🔧 **What This Code Does:**\n1. ✅ **Groups** the dataset by **month names** (e.g., January, February, etc.)\n2. 📈 **Aggregates** total listening time (`hours_played`) for each month, **across all years**\n3. 🗓️ **Sorts** the months in chronological order (from **January to December**) using the `sort_df_months` function\n4. 🧹 **Cleans up** the output by removing the temporary numeric month column (`month_added_n`)\n\n##### 🎯 **Purpose:**\nTo uncover **trends that repeat year-over-year**, such as:\n- Do I listen more during certain seasons?\n- Are there consistent drops or spikes in specific months?\n- How does monthly listening compare when averaged across multiple years?\n\n","metadata":{}},{"cell_type":"code","source":"# Set figure size for better visualization of monthly trends\ndefault_figsize = (10, 4)  # Wider than default to accommodate all months\n\n# Calculate total hours played per month across all years\nhours_by_month = sum_by(\n    df=df_merged,\n    criteria1='month',        # Group by month name\n    criteria2='hours_played'  # Sum hours played\n)\n\n# Sort months chronologically (January to December)\nhours_by_month_sorted = sort_df_months(\n    df=hours_by_month,\n    month_col='month'  # Column containing month names\n)\nhours_by_month_sorted.drop('month_added_n',axis=1)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:52.838603Z","iopub.execute_input":"2025-05-25T00:08:52.838967Z","iopub.status.idle":"2025-05-25T00:08:52.866915Z","shell.execute_reply.started":"2025-05-25T00:08:52.838935Z","shell.execute_reply":"2025-05-25T00:08:52.865946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate the visualization with improved formatting\nplot_(\n    df=hours_by_month_sorted,\n    x='month',          # Months on x-axis\n    y='hours_played',   # Hours played on y-axis\n    x_label='Month',    # More accurate than 'Genres'\n    y_label='Total Hours', \n    title=\"Monthly Listening Hours (2018-2025)\",  # Clear time period\n    inverted=False      # Vertical bar chart\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:52.867914Z","iopub.execute_input":"2025-05-25T00:08:52.868157Z","iopub.status.idle":"2025-05-25T00:08:53.404001Z","shell.execute_reply.started":"2025-05-25T00:08:52.868138Z","shell.execute_reply":"2025-05-25T00:08:53.403029Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔝 **Top Listening Months (Across All Years)**\n\n- **August** stands out as the **most listened-to month** with a staggering **235.69 hours (~9.8 days)**.\n- **October (185.06 hrs)** and **September (179.58 hrs)** follow closely behind, showing strong engagement in late summer and early fall.\n- **February (171.70 hrs)** also ranks high, suggesting that I tend to listen more during the colder months of the year.\n\n##### 📉** Lowest Listening Months**\n\n- **June (70.01 hrs)**, **May (79.81 hrs)**, and **April (99.31 hrs)** are the lowest three months, indicating a notable lull in usage during **early spring through mid-summer**.\n- This could reflect:\n  - Increased outdoor activity\n  - Less time at home\n  - Shifts toward other media types (e.g., podcasts, video content)\n  - Potential data gaps or reduced app usage during these periods\n\n\n##### 📈 **Seasonal Patterns & Behavioral Insights**\n\nThere’s a clear **seasonal trend** in my listening behavior:\n\n- **Peak Listening: Late Summer to Early Winter (August–November)**\n  - These months consistently rank highest in playback time.\n  - Could align with back-to-school routines, cooler weather, or indoor leisure activities.\n\n- **Lowest Listening: Spring into Early Summer (April–June)**\n  - Lower totals may be due to more active lifestyles, warmer weather, or less reliance on background music.\n\n- **Winter Dip?** While December is still relatively high (152.19 hrs), it doesn’t dominate like August or October — possibly due to holiday distractions or varied end-of-year schedules.\n\n##### 🧠 **Observations**\n\n- **August Dominance**: The standout performance of **August** suggests this month holds special significance in my listening habits — perhaps tied to travel, work rhythm, or personal preference.\n- **Consistency Over Time**: These trends span multiple years, meaning they aren't just anomalies of one specific year — they represent **recurring behavior**.\n- **Possible Lifestyle Correlation**: my listening peaks when you're likely indoors or engaged in focused activities — e.g., working from home, studying, or relaxing during cooler months.","metadata":{}},{"cell_type":"markdown","source":"#### **6.1.4 📅 Examining Monthly Playback for Each Year (2018–2025)**\n\nThis analysis dives deeper into **Spotify listening behavior by month**, but now **separately for each year** from **2018 to 2025**. The goal is to uncover:\n- How my listening habits changed **year over year**\n- Whether specific months consistently stood out (e.g., July or August)\n- If there were any **unique patterns in certain years**\n\n##### 🔧 **What This Code Does:**\n1. ✅ Iterates through each year from **2018 to 2025**\n2. 📌 Filters the dataset for each individual year\n3. 📊 Groups by `year` and `month`, then calculates total playback hours per month\n4. 📈 Sorts each yearly result by total playback hours (from highest to lowest)\n5. 📥 Stores and prints each year’s monthly breakdown\n\n##### 🎯 **Purpose:**\nTo identify:\n- **Year-specific trends**: Were some years more consistent than others?\n- **Seasonal peaks and drops**: Did the same months stand out every year?\n- **Changes over time**: Has listening behavior evolved from 2018 to 2025?\n\n","metadata":{}},{"cell_type":"code","source":"years = list(range(2018,2026))\nyear_dfs= []\nfor year in years:\n    condition = df_merged.year==year\n    monthly_listenning_hours= (\n        df_merged[condition].groupby(['year','month'])\n        .agg(month_playback_hours=('hours_played','sum'))\n        .sort_values(['year','month_playback_hours'],ascending=False).reset_index()\n    )\n    year_dfs.append(monthly_listenning_hours)\n    display(year,monthly_listenning_hours)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:53.404972Z","iopub.execute_input":"2025-05-25T00:08:53.405414Z","iopub.status.idle":"2025-05-25T00:08:53.55698Z","shell.execute_reply.started":"2025-05-25T00:08:53.405379Z","shell.execute_reply":"2025-05-25T00:08:53.55611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"year = 2019\nyear_dfs.pop(5)\nyear_dfs.pop(0)\nfor plot in year_dfs:\n    default_figsize=(10,6)\n    plot_(df=plot,\n              x='month',\n              y='month_playback_hours',\n              y_label='Top 10 Genres',\n              x_label='Numbers of hours of playback',\n              title=f'Monthly playback hours for the year {year}',\n              inverted=False)\n    year +=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:53.557962Z","iopub.execute_input":"2025-05-25T00:08:53.55838Z","iopub.status.idle":"2025-05-25T00:08:56.772066Z","shell.execute_reply.started":"2025-05-25T00:08:53.558346Z","shell.execute_reply":"2025-05-25T00:08:56.771092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Monthly Playback Trends by Year (2018–2025)**\n\n##### 📈 **General Listening Behavior**\n- **2020** remains the peak year overall, with **July** being the single most-listened month across all years (**66.8 hrs**).\n- **August** consistently ranks as a top listening month — especially strong in **2022, 2023**, and **2024**.\n- **April 2020** and **December 2025** have notably low listening hours, suggesting possible data gaps or behavioral shifts.\n\n##### 🌕 **Seasonal Patterns**\n- **Late summer to fall (August–November)** is typically the **most active listening period** across multiple years.\n- **Spring (March–May)** often sees reduced listening — particularly in **2020**, **2023**, and **2024**.\n\n##### 📅 **Year-Specific Highlights**\n\n- **2018**: Very limited data — only **September** shows activity (**0.61 hrs**).\n- **2019**: Listening starts building — **October** leads with **49.25 hrs**.\n- **2020**: Clear peak in **July**, followed by high listening through late-year — likely linked to pandemic-related lifestyle changes.\n- **2021**: Lower overall engagement; **December** is top month (**35.35 hrs**) — a shift from earlier trends.\n- **2022**: Strong start with **February** leading (**50.42 hrs**) — more evenly distributed listening throughout the year.\n- **2023**: **August** dominates again (**52.84 hrs**), but **December** has very low playback (**0.24 hrs**).\n- **2024**: More balanced usage — **August, February, and November** all above **29 hrs**.\n- **2025 (partial)**: Only four months available — **January** is highest (**50.31 hrs**), indicating potentially renewed heavy usage.\n\n##### 🔄 **Consistent Observations**\n- **August** stands out across multiple years as a high-listening month.\n- **January** showed increased listening in **2025** and **2024**, suggesting growing significance.\n- **December** varied widely — high in **2020 and 2021**, but very low in **2023**.\n- ---\n","metadata":{}},{"cell_type":"markdown","source":"#### **6.1.5 Weekly Listening Patterns Analysis**\n\n1. **Groups Data by Weekday**:  \n   - Uses `groupby('weekday')` to split data into 7 groups (Monday-Sunday).\n\n2. **Aggregates Listening Hours**:  \n   - `hours_played=('hours_played', 'sum')` calculates **total listening time** per weekday.  \n   - `day_of_the_week=('weekday', 'first')` preserves weekday labels (e.g., \"Monday\").","metadata":{}},{"cell_type":"code","source":"by_weekdays= (\n    df_merged.groupby('weekday_n')\n    .agg(hours_played=('hours_played','sum'),weekday=('weekday','first'))\n    .reset_index().sort_values('weekday_n').drop('weekday_n',axis=1)\n)\nby_weekdays","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:56.773169Z","iopub.execute_input":"2025-05-25T00:08:56.773448Z","iopub.status.idle":"2025-05-25T00:08:56.79591Z","shell.execute_reply.started":"2025-05-25T00:08:56.773425Z","shell.execute_reply":"2025-05-25T00:08:56.794997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize = (8,3)\nplot_(by_weekdays,\\\n          x='weekday',\\\n          y='hours_played',\\\n          x_label='weekday',\\\n          y_label='hours_played',\\\n          title='hours played by day of the week for the whole period covered by the dataset',\\\n          inverted=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:56.797244Z","iopub.execute_input":"2025-05-25T00:08:56.797598Z","iopub.status.idle":"2025-05-25T00:08:57.11552Z","shell.execute_reply.started":"2025-05-25T00:08:56.797566Z","shell.execute_reply":"2025-05-25T00:08:57.114489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Weekly Listening Patterns (2018–2025)**\n\n##### 📝 **Top Observations**\n\n- 🥇 **Thursday is the most-listened weekday**, with over **285 hours** — slightly outpacing other days.\n- 🥉 **Saturday has the least playback time**, suggesting reduced Spotify usage on weekends, possibly due to:\n  - More social or outdoor activity\n  - Less structured routine\n  - Shift toward podcasts, videos, or other platforms\n\n- 📅 **Tuesday through Friday** show the **highest and most consistent listening**, indicating stronger engagement during mid-to-late workweek.\n\n- 🧠 **Slight weekday vs. weekend divide**: Slightly more listening occurs during the workweek overall, which could point to:\n  - Music being used for focus/work\n  - Background listening while commuting or studying\n  - Routine-based habits forming during weekdays\n\n##### 🔄 **Behavioral Pattern Summary**\n\n- **Peak Engagement**: Midweek (**Thursday**) sees the most listening — possibly tied to a need for motivation, focus, or relaxation as the week progresses.\n- **Weekend Dropoff**: **Saturday** consistently lags behind all other days, suggesting lifestyle changes or alternative entertainment preferences during free time.\n\n---","metadata":{}},{"cell_type":"markdown","source":"####  **6.1.6 Hourly Listening Frequency Analysis**\n\n#### **Purpose**\nThis code analyzes listening patterns by hour of day to identify peak engagement periods.\n\n\n\n#### **Key Variables**\n| Variable | Type | Description |\n|----------|------|-------------|\n| `hour` | int | Hour of day (0-23) |\n| `count` | int | Number of plays during that hour |\n","metadata":{}},{"cell_type":"code","source":"\n\nhour_dist = (\n    df_merged.groupby('hour')\n    .agg(count=('ts','count'))\n    .sort_values('count',ascending=False)\n    .reset_index()\n)\nhour_dist","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:57.116516Z","iopub.execute_input":"2025-05-25T00:08:57.116737Z","iopub.status.idle":"2025-05-25T00:08:57.133548Z","shell.execute_reply.started":"2025-05-25T00:08:57.116719Z","shell.execute_reply":"2025-05-25T00:08:57.132402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndefault_figsize = (12,4)\nplot_(hour_dist,\\\n          x='hour',\\\n          y='count',\\\n          x_label='hour of the day',\\\n          y_label='count',\\\n          title='hours played by hour of the day for the whole period covered by the dataset',\\\n          inverted=False)\n \n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:57.134557Z","iopub.execute_input":"2025-05-25T00:08:57.13488Z","iopub.status.idle":"2025-05-25T00:08:58.525825Z","shell.execute_reply.started":"2025-05-25T00:08:57.134852Z","shell.execute_reply":"2025-05-25T00:08:58.524828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Hourly Listening Frequency**\n\n- 🕒 **Peak Listening Hour**: **12 PM (noon)** is the most frequent listening hour with **2,573 plays** — possibly linked to lunch breaks or midday focus/music sessions.\n\n- 📈 **High Engagement Window**: **11 AM – 1 PM** and **5 PM – 10 PM** show consistently high play counts, indicating strong usage during late morning, early afternoon, and evening hours.\n\n- 🌙 **Lowest Listening Hours**: **4 AM – 5 AM** have the fewest plays (**107 and 131**, respectively), aligning with typical sleeping hours.\n\n- 🔄 **Drop-off After Midnight**: Significant decline in plays after **midnight**, with sharp drops around **3 AM – 5 AM**.\n\n- ⏰ **Morning Surge**: A noticeable increase starting from **7 AM onward**, peaking at **10 AM (1,402 plays)** — suggests Spotify is used regularly during morning routines.\n\n  ----","metadata":{}},{"cell_type":"markdown","source":"#### **6.1.7 Time series analysis by sequential Month, Day, Hour**\n\n##### **6.1.7.1 Sequential Month**\n\nInsights Specific to Analysis by `month_sequential_n`\n\n##### Sequential Trends\n- **Sequential Order:** The use of `month_sequential_n` allows us to observe trends in a strictly sequential manner. This means we can track changes and patterns over time in a linear fashion, which is particularly useful for identifying long-term trends or cyclical patterns that might not be immediately apparent when looking at yearly data.\n- **Cumulative Analysis:** By analyzing the data in a sequential order, we can perform cumulative analysis, such as cumulative sums of `hours_played` over time. This can help in understanding the growth or decline in listening activity over the entire period.\n\n##### Comparison with Previous Analysis\n- **Granularity:** The sequential analysis provides a more granular view compared to yearly analysis. It allows us to see month-to-month changes, which can be crucial for identifying short-term fluctuations that might be averaged out in yearly data.\n- **Temporal Patterns:** Sequential analysis can reveal temporal patterns that are not evident in yearly data. For example, we can identify specific months where there are sudden spikes or drops in listening activity, which might be related to specific events or seasonal changes.\n","metadata":{}},{"cell_type":"code","source":"df_month_playback=df_merged.groupby(['month_sequential_n'])\\\n    .agg({'hours_played':'sum','year':'first','month':'first'}).reset_index()\n\nprint(\"statistics of day_sequential_n\",df_month_playback.month_sequential_n.describe())\nprint(\"statistics of hours_played\",df_month_playback.hours_played.describe())\nprint()\nprint(df_month_playback.sort_values('month_sequential_n').head(60))\nprint(df_month_playback.sort_values('month_sequential_n').tail(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:58.526618Z","iopub.execute_input":"2025-05-25T00:08:58.526904Z","iopub.status.idle":"2025-05-25T00:08:58.552711Z","shell.execute_reply.started":"2025-05-25T00:08:58.526881Z","shell.execute_reply":"2025-05-25T00:08:58.551635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize = (20,10)\nplot_(df_month_playback,\\\n          x='month_sequential_n',\\\n          y='hours_played',\\\n          x_label='month_sequential_n',\\\n          y_label='not_skipped_count',\\\n          title='Playbapck count by months',\\\n          inverted=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:08:58.553543Z","iopub.execute_input":"2025-05-25T00:08:58.553817Z","iopub.status.idle":"2025-05-25T00:09:08.722898Z","shell.execute_reply.started":"2025-05-25T00:08:58.553789Z","shell.execute_reply":"2025-05-25T00:09:08.721937Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Sequential Monthly Playback Trends (`month_sequential_n`)**\n\n##### 📊 **Summary Statistics**\n- **Total months tracked**: 70 (from `month_sequential_n = 0` to `69`)\n- **Average monthly listening**: ~**25.23 hours**\n- **Most listened month**: **66.8 hrs (Jul 2020)**\n- **Least listened month**: **0.24 hrs (Dec 2023)**\n\n##### 📈 **Long-Term Listening Trends**\n\n- 📶 **Initial Phase (Months 0–6)**:\n  - Low activity at the start (**month 0 = 0.61 hrs**), followed by a sharp rise in **August 2019 (month 2 = 45.69 hrs)**.\n  - Indicates **early engagement growth**, possibly as music preferences were being defined.\n\n- 🧠 **Peak Engagement**:\n  - **July 2020 (month 13)** marks the highest listening month with **66.8 hrs**.\n  - This aligns with earlier findings of increased Spotify usage during 2020 — likely due to lifestyle shifts from global events.\n\n- 📉 **Recent Decline**:\n  - A noticeable drop in listening starts around **late 2024**, with **Apr 2025 (month 69 = 7.73 hrs)** showing one of the lowest values overall.\n  - Could indicate reduced music discovery, lifestyle changes, or data capture issues.\n##### 🔄 **Seasonal & Cyclical Patterns**\n\n- 🎯 **Mid-Year Peaks**:\n  - High listening in **July (2020, 2022, 2023, 2024)** suggests a recurring mid-year peak.\n  - Could be linked to seasonal moods, vacations, or playlist habits.\n\n- 🌦️ **Winter Listening**:\n  - Months like **December 2020 (40.58 hrs)** and **January 2022 (34.05 hrs)** also show consistent increases — possibly tied to holiday time or indoor routines.\n\n- ⛱️ **Summer/Low Periods**:\n  - Some summers see dips (e.g., **May 2022 had only 5.94 hrs**) suggesting reduced engagement during certain warm seasons.\n\n##### 📅 **Behavioral Highlights**\n\n- 📆 **Spotify Growth Timeline**:\n  - **2018–2019**: Initial phase with moderate but growing engagement.\n  - **2020**: Peak year overall — high listening across multiple months.\n  - **2021**: Slight decline, especially in mid-year months like **July (0.47 hrs)**.\n  - **2022–2023**: Recovery and renewed high engagement, especially in fall months.\n  - **2024–2025**: Gradual decline, with lower consistency in listening behavior.\n\n##### 💡 **Practical Takeaways**\n\n- **Music Curation Timing**: July and late fall months (October–November) appear ideal for deep listening or playlist updates.\n- **Engagement Drops**: April–May and some summer months may represent low-engagement windows — useful for planning releases or marketing outside of these periods.\n- **Long-Term Shifts**: The recent drop in 2025 suggests either behavioral change or a need to re-engage with new content or playlists.\n---","metadata":{}},{"cell_type":"markdown","source":"##### **6.1.7.2 Doing the same but with sequential days**:","metadata":{}},{"cell_type":"code","source":"df_day_playback=df_merged.groupby(['day_sequential_n'])\\\n    .agg({'hours_played':'sum','year':'first','month':'first','day':'first'}).reset_index()\n\nprint(\"statistics of day_sequential_n\",df_day_playback.day_sequential_n.describe())\nprint(\"statistics of hours_played\",df_day_playback.hours_played.describe())\nprint()\ndf_day_playback.sort_values('hours_played',ascending=False).head(60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:08.723706Z","iopub.execute_input":"2025-05-25T00:09:08.723945Z","iopub.status.idle":"2025-05-25T00:09:08.754615Z","shell.execute_reply.started":"2025-05-25T00:09:08.723925Z","shell.execute_reply":"2025-05-25T00:09:08.753803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 Key Insights: Daily Playback Trends (`day_sequential_n`)\n\n##### 📊 **Summary Statistics**\n- **Total days tracked**: **1,508**\n- **Average daily listening**: ~**1.17 hours**\n- **Most listened day**: **6.55 hours (Jul 23, 2020)**\n- **Least listened day**: **0.0016 hours (~6 seconds)**\n\n \n\n##### 🥇 **Top Listening Days**\n| Date          | Hours Played | Notes |\n|---------------|--------------|-------|\n| Jul 23, 2020  | **6.55**     | Peak of 2020 listening surge |\n| Sep 5, 2020   | **6.32**     | High engagement during mid-2020 |\n| Sep 11, 2023  | **6.30**     | One of the most-listened recent days |\n| Sep 2, 2020   | **6.29**     | Another top day in peak year |\n| Jul 14, 2020  | **6.21**     | Part of July 2020 dominance |\n\n- **July 2020** dominates the top daily list — reinforcing it as a standout month for listening.\n- **High-value days** are spread across multiple years — especially **2020, 2023**, and **2024/2025**.\n\n \n\n##### 📈 **Behavioral Patterns**\n\n- 🌟 **Daily Listening Peaks**:\n  - The **top 10 days** range from **~5–6.5 hrs/day**, indicating intense listening sessions likely tied to mood, work focus, or emotional states.\n\n- 📉 **Gradual Decline in Intensity**:\n  - While high-listening days still occur in **2023–2025**, their frequency is lower than in 2020.\n\n- ⏰ **Typical Day**:\n  - Most days fall below **2 hours played**, with a median of **~0.96 hours** — suggesting Spotify is often used in background or session-based modes.\n\n \n\n##### 🗓️ **Notable Observations**\n\n- 🧠 **2020 Dominance**: 10+ of the top 60 listening days occurred in **2020**, especially concentrated in **July**.\n- 📆 **Seasonal Repeats**: Some months like **September** and **February** appear frequently in high-listening days across different years.\n\n \n\n##### 💡** Practical Takeaways**\n\n- **Mood & Music**: High-listening days may correlate with emotional or productivity states — worth exploring with mood or activity logs.\n- **Playlist Engagement**: Days like **Jul 23, 2020** could represent deep dives into specific artists or genres (e.g., Sigur Rós).\n- **Spotify Habits**: I tend to use Spotify more **intensively on certain days**, rather than evenly throughout the week/month.\n","metadata":{}},{"cell_type":"markdown","source":"##### **6.1.7.3 Doing the same but with sequential hours:**","metadata":{}},{"cell_type":"code","source":"df_hour_playback=df_merged.groupby(['hour_sequential_n'])\\\n    .agg({'hours_played':'sum','year':'first','month':'first','day':'first','hour':'first','ts':'first'}).reset_index()\ndf_hour_playback['hours_played'] = np.round(df_hour_playback['hours_played'],1)\nprint(df_hour_playback['hour_sequential_n'].describe())\nprint(df_hour_playback['hours_played'].describe())\ndf_hour_playback.sort_values('hours_played',ascending=False).head(60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:08.755545Z","iopub.execute_input":"2025-05-25T00:09:08.755779Z","iopub.status.idle":"2025-05-25T00:09:08.791647Z","shell.execute_reply.started":"2025-05-25T00:09:08.75576Z","shell.execute_reply":"2025-05-25T00:09:08.790841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Sequential Hourly Playback Trends (`hour_sequential_n`)**\n\n##### 📊 **Summary Statistics**\n- **Total hours tracked**: **7,207**\n- **Average hourly listening**: ~**0.24 hours (~14 minutes)**\n- **Most listened hour**: **1 full hour played (Mar 10, 2023 at 18:05)**\n- **Least listened hour**: **0 hours (many instances)**\n\n \n\n##### 🥇 **Top Listening Hours**\n| Date & Time                | Hours Played | Notes |\n|----------------------------|--------------|-------|\n| Mar 10, 2023 @ 18:05       | **1.0**      | Most-listened single hour |\n| Oct 14, 2022 @ 20:00       | **0.9**      | Evening peak |\n| Jul 14, 2020 @ 06:01       | **0.9**      | Early morning session |\n| Jan 30, 2022 @ 13:00       | **0.9**      | Midday usage |\n| Sep 12, 2023 @ 23:02       | **0.9**      | Late-night listening |\n\n- Many of the top hours align with **high daily listening days** previously identified.\n- **2020 remains a standout year**, especially for long, immersive sessions.\n\n\n##### ⏰ **Behavioral Patterns**\n\n- 🧠 **Intensive Listening Blocks**:\n  - The top 60 hours all have **at least 0.8 hours (48 minutes)** played — suggesting focused or background listening over extended periods.\n  - These often appear in clusters, indicating multi-hour sessions.\n\n- 🕐 **Time-of-Day Preferences**:\n  - High-playback hours span **early mornings**, **mid-days**, and **late nights** — showing no strict time preference.\n  - However, **evening and late night** (e.g., 20:00–23:00) appear more frequently among high-listening hours.\n\n- 🌙 **Late-Night Sessions**:\n  - Multiple entries between **10 PM – 2 AM**, possibly linked to relaxation, work, or insomnia-driven listening.\n\n \n\n##### 📅 **Observations**\n\n- 📆 **Session-Based Usage**:\n  - I tend to listen for **longer durations during specific blocks**, rather than short bursts throughout the day.\n  - This supports earlier insights where certain **days** or **months** dominate total playback.\n\n- 📈 **Spotify as Ambient Companion**:\n  - Many hours show near-full playback (0.8–1.0 hrs), suggesting Spotify is used as background music while working, relaxing, or commuting.\n\n- 🧩 **Noisy Data?**:\n  - Some entries show exactly **1.0 hour**, which could indicate either:\n    - A full-hour playlist looping\n    - Rounded data\n    - Or streaming while performing another activity\n\n##### 💡 **Practical Takeaways**\n\n- 🎯 **Peak Engagement Times**:\n  - Use these insights to schedule new releases, podcasts, or playlists around my most active listening windows.\n  \n- 📅 **Behavioral Routines**:\n  - Explore if these high-listening hours align with **work, study, travel**, or **emotional states**.\n\n- 🎵 **Playlist Optimization**:\n  - Long listening blocks suggest opportunities for curated **focus playlists**, **ambient mixes**, or **multi-hour sessions** tailored to specific moods or tasks.\n","metadata":{}},{"cell_type":"markdown","source":"### **6.2 Genres, Artists and Tracks**\n\n##### **6.2.1 🎧 Top 10 Music Genres by Listening Time**\n\nThis section explores which **music genres** you've listened to the most, based on total **hours played** across all years.\n\n##### 🔧 **What This Code Does:**\n1. ✅ Groups the data by **genre**\n2. 📊 Aggregates total listening time (`hours_played`) per genre\n3. 📈 Sorts genres in descending order by total listening time\n4. 🏆 Keeps only the **top 10 genres**\n5. 🔄 Resets the index for easier display or visualization\n\n##### 🎯 **Purpose:**\nTo understand:\n- Which genres dominate my Spotify listening habits\n- Whether my music taste is diverse or focused on a few key genres\n- How much time you’ve spent listening to each genre overall","metadata":{}},{"cell_type":"code","source":"hours_by_genres = (\n    df_merged.groupby('Genres')\n    .agg({'hours_played':'sum'})\n    .sort_values('hours_played',ascending=False)\n)\n\nhours_by_genres=hours_by_genres.head(10).reset_index()\nhours_by_genres","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:08.792588Z","iopub.execute_input":"2025-05-25T00:09:08.7929Z","iopub.status.idle":"2025-05-25T00:09:08.809989Z","shell.execute_reply.started":"2025-05-25T00:09:08.792862Z","shell.execute_reply":"2025-05-25T00:09:08.809086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize=(20,6)\nplot_(df=hours_by_genres,\n          x='Genres',\n          y='hours_played',\n          y_label='Top 10 Genres',\n          x_label='Numbers of hours of playback',\n          title='My top 10 Genres by hours of playback since 2018',\n          inverted=True)","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:08.811073Z","iopub.execute_input":"2025-05-25T00:09:08.811457Z","iopub.status.idle":"2025-05-25T00:09:09.337138Z","shell.execute_reply.started":"2025-05-25T00:09:08.811428Z","shell.execute_reply":"2025-05-25T00:09:09.336248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Top 10 Music Genres by Listening Time**\n\n- 🎸 **Diverse Taste**: my top genres span **classical, rock, folk, pop, and niche regional styles**, indicating a broad and eclectic musical palette.\n\n- 📊 **Top Genre**: **Post-rock, Dream Pop** leads with **37.67 hours** — suggesting a strong preference for atmospheric, instrumental, and mood-driven music.\n\n- 🎻 **Classical Influence**: Multiple classical subgenres appear in the top 10, especially those combining **piano, chamber music, and orchestral elements**, showing a deep engagement with classical music.\n\n- 🇮🇹🎵 **Regional & Niche Genres**: Presence of **Canzone Napoletana**, **Italian singer-songwriter**, and **Latin Folk** highlights appreciation for regional and culturally rich music styles.\n\n- 🌍 **Genre Fusion**: Several entries feature **genre blends**, such as \"Progressive Rock, Psychedelic Rock, Classic Rock\" — reflecting open exploration across eras and styles.\n\n- ⏰ **Polka Surprise**: **Polka** ranks highly (**29.8 hrs**), indicating a unique or nostalgic listening habit not typically seen in mainstream Spotify analyses.\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"#### **6.2.2🔍 Deep Dive into \"Post-Rock, Dream Pop\"**\n\nSince **\"post-rock, dream pop\"** is my **most-listened-to genre** (~32.4 hours total), we're now diving deeper into which **artists and tracks** contributed most to that listening time.\n\n##### 🔧 **What This Code Does:**\n1. ✅ Uses the custom function `get_genre_artists()` to:\n   - Filter for the **genre tag**: `'post-rock,dream pop'`\n   - Calculate total **hours played per artist**\n   - Count the number of **tracks or entries per artist**\n2. 📈 Returns two DataFrames:\n   - `df_genre_sum`: Top artists by **total listening time**\n   - `df_genre_count`: Top artists by **track count**\n3. 🎯 Limits results to the **top 20** artists for each\n","metadata":{}},{"cell_type":"code","source":"df_genre_count,df_genre_sum = get_genre_artists('post-rock,dream pop',df_merged)\ndf_genre_sum=df_genre_sum.reset_index(drop=True).head(20)\ndf_genre_count = df_genre_count.reset_index(drop=True).head(20)\ndf_genre_sum","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:09.338124Z","iopub.execute_input":"2025-05-25T00:09:09.338484Z","iopub.status.idle":"2025-05-25T00:09:09.381774Z","shell.execute_reply.started":"2025-05-25T00:09:09.338453Z","shell.execute_reply":"2025-05-25T00:09:09.380964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑**Key Insights: Deep Dive into \"Post-Rock, Dream Pop\"**\n\n- 🎸 **Dominant Artist**: **Sigur Rós** accounts for the vast majority of listening time in this genre — **2,259.86 minutes (~37.67 hours)** — suggesting a deep and sustained engagement with their atmospheric, instrumental style.\n\n- 🧠 **No Other Artists in Top Playback Time**: The data shows **no other artists** contributing significantly to the \"post-rock, dream pop\" genre in terms of playback time — indicating that my listening was heavily centered around **Sigur Rós**.\n","metadata":{}},{"cell_type":"markdown","source":"#### **6.2.3 Deep dive: Top Sigur Rós Tracks**","metadata":{}},{"cell_type":"code","source":"sigur = get_top_tracks_by_artist(df_merged, 'Sigur Rós', top_n=10)\nsigur.minutes_played.sum()/60\n\nprint(sigur.columns)\n\n\n#merging duplicate songs by summing their playback time\n\ndisplay(sigur.reset_index(drop=True),sigur.minutes_played.sum())","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:09.382687Z","iopub.execute_input":"2025-05-25T00:09:09.382957Z","iopub.status.idle":"2025-05-25T00:09:09.437632Z","shell.execute_reply.started":"2025-05-25T00:09:09.382936Z","shell.execute_reply":"2025-05-25T00:09:09.436682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize=(12,4)\nplot_(df=sigur,\n          x='master_metadata_track_name',\n          y='minutes_played',\n          x_label='Total playback time (minutes)',\n          y_label='Months',\n          title='My top 10 songs by Sigur Rós\\n (2020-2025)',\n          inverted=True\n         )","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:09.438529Z","iopub.execute_input":"2025-05-25T00:09:09.438829Z","iopub.status.idle":"2025-05-25T00:09:10.331469Z","shell.execute_reply.started":"2025-05-25T00:09:09.438806Z","shell.execute_reply":"2025-05-25T00:09:10.330288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Top Sigur Rós Tracks**\n\n- ⏰ **Total Listening Time for Sigur Rós**: Over **37.6 hours**, all attributed to Sigur Rós — confirming their dominance in my \"post-rock, dream pop\" listening.\n\n- 🎵 **Top Track**: **\"Svo Hljótt\"** with **4.65 hours** of playback — nearly **18%** of total genre listening time.\n\n- 📅 **Most Active Year**: Most top tracks were played in **2020**, aligning with my overall peak listening year.\n\n- 🧩 **Track Variety**: While playback is led by a few key songs like **\"Sé Lest\"**, **\"Ágætis Byrjun\"**, and **\"Svefn-g-englar\"**, you’ve engaged with a **range of tracks**, not just one or two songs.\n\n- 🕒 **Long Engagement**: Multiple plays across years (including 2025) suggest **long-term emotional or ambient connection** to this band.\n\n---","metadata":{}},{"cell_type":"markdown","source":"#### **6.2.4🎤 Top Artists by Total Playback Hours**\n\nThis analysis aggregates my **Spotify listening data** to show which **artists** you've listened to the most, based on **total hours played**. It also includes the **average song length** for each artist, giving insight into whether my engagement comes from long sessions with short songs or fewer plays of longer tracks.\n\n##### 🔧 **What This Code Does:**\n1. ✅ Groups the dataset by **artist name**\n2. 📊 Aggregates:\n   - Total playback hours per artist\n   - Average song duration (in minutes)\n3. 📈 Sorts artists by total playback time in descending order\n4. 🔄 Rounds average song duration to 2 decimal places (converted from milliseconds)\n5. 🏆 Shows the top 20 artists\n","metadata":{}},{"cell_type":"code","source":"top_artists_hours = (\n    df_merged.groupby('master_metadata_album_artist_name')\n    .agg(total_playback_hours=('hours_played','sum'),average_song_duration=('Duration (ms)','mean'))\n    .sort_values('total_playback_hours',ascending=False)\n    .reset_index()\n)\ntop_artists_hours.average_song_duration = np.round(top_artists_hours.average_song_duration /(1000*60),2)\ntop_artists_hours.head(20)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.332755Z","iopub.execute_input":"2025-05-25T00:09:10.333092Z","iopub.status.idle":"2025-05-25T00:09:10.367816Z","shell.execute_reply.started":"2025-05-25T00:09:10.33306Z","shell.execute_reply":"2025-05-25T00:09:10.366772Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Top Artists by Total Playback Hours**\n\n- 🎼 **Classical Dominance**: The top three artists — **Beethoven, Sigur Rós, and Mozart** — are all associated with **longer average song durations**, contributing to their high total listening hours.\n\n- 🧠 **Sigur Rós Impact**: Despite not having the longest average track length, **Sigur Rós** ranks #2 overall in playback time (**45.13 hrs**) — reinforcing their emotional and atmospheric appeal over extended listening sessions. (total hours look bigger here because it includes also songs that lack Genres metadata)\n\n- ⏱️ **Beethoven Leads by Far**: With an **average song duration of 12.66 minutes**, Beethoven’s music contributes to **83.51 total listening hours** — the highest in my library. This suggests frequent use during focused or passive listening moments.\n\n- 🕰️ **Long Tracks = High Engagement**: Artists like **Wagner**, **Pink Floyd**, and **Stars of the Lid** also have long average song lengths, indicating a preference for **immersive, extended listening experiences**.\n\n- 🌍 **Genre & Cultural Diversity**: my top artists span **classical, ambient, rock, folk, and Latin American music**, showcasing a globally influenced and emotionally rich listening profile.\n\n- 📊 **Modern Rock Presence**: Bands like **Polo & Pan**, **First Aid Kit**, and **Oasis** reflect consistent engagement with contemporary and alternative sounds.","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"#### **6.2.5 📈 Top Artists by Play Count (Number of Plays)**\n\nThis analysis focuses on how frequently you've played songs from each artist — not how long I listened, but **how many times I hit play**. This gives insight into which artists I return to most often. The results should be less biased than playback time because as shown by the previous analysis, song duration affects playback time and the highly ranked ones are more likely to be the ones with long song durations.\n\n##### 🔧 **What This Code Does:**\n1. ✅ Groups the dataset by **artist name**\n2. 📊 Counts the number of times each artist appears (i.e., how often their songs were played)\n3. 📈 Sorts the list in descending order by play count\n4. 🔄 Resets the index for easier readability\n5. 🏆 Shows the top 20 most-played artists","metadata":{}},{"cell_type":"code","source":"\ntop_artists_by_count=(\n    df_merged\n    .groupby('master_metadata_album_artist_name')\n    .agg(count=('ts','count'))\n    .sort_values('count',ascending=False)\n    .reset_index()\n)\ntop_artists_by_count.head(20)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.368858Z","iopub.execute_input":"2025-05-25T00:09:10.369478Z","iopub.status.idle":"2025-05-25T00:09:10.399238Z","shell.execute_reply.started":"2025-05-25T00:09:10.369443Z","shell.execute_reply":"2025-05-25T00:09:10.398353Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Top Artists by Play Count**\n\n- 🎼 **Classical Reigns Supreme**: 9 out of the top 10 most-played artists are classical or historically rooted musicians — showing how frequently I return to these artists, regardless of track length.\n\n- 🧠 **Beethoven Tops Both Time & Frequency**: **Beethoven** is #1 in both **total playback hours** and **play count (659 plays)** — proving consistent, long-term engagement.\n\n- ⚖️ **Sigur Rós: High Playback Time, Moderate Play Count**: Sigur Rós ranks **#6 by play count (444 plays)** but **#2 by total listening time (45.13 hrs)** — indicating longer, more immersive sessions when played.\n\n- 📊 **Bach vs. Mozart**: **Bach** has slightly more plays (**587**) than **Mozart (510)**, but Mozart ranks higher in playback time — suggesting **Mozart’s tracks are generally longer**.\n\n- 🌍 **Latin Influence Strong**: Artists like **Atahualpa Yupanqui (536 plays)**, **Compay Segundo (319)**, and **Inti-Illimani (229)** show deep, frequent engagement with Latin American folk and traditional music.\n\n- 🕰️ **Long Tracks ≠ Frequent Plays**: Classical composers like **Wagner** and **Vivaldi** appear high in both lists — showing that despite long song durations, they’re still frequently revisited.\n\n---","metadata":{}},{"cell_type":"markdown","source":"### **6.3 Song Adding Habits**\n\n#### **6.3.1 Yearly trends**\n\nTo understand when new songs were added to the library, we:\n- Filtered for tracks that were liked (`liked == True`),\n- Removed duplicate track names to count only unique songs,\n- Grouped by `year_added` to see how many songs were added each year.\n\nThis gives insight into curation habits and periods of active music discovery.","metadata":{}},{"cell_type":"code","source":"condition = df_merged['liked'] == True\nunique_track_names = df_merged[condition].drop_duplicates(subset=['master_metadata_track_name','year_added'])\nadded_by_year=unique_track_names.groupby('year_added').agg({'ts':'count'}).reset_index().rename({'ts':'count'},axis=1)\nprint(f\"total added:{added_by_year['count'].sum()}\")\nadded_by_year\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.400125Z","iopub.execute_input":"2025-05-25T00:09:10.400412Z","iopub.status.idle":"2025-05-25T00:09:10.446375Z","shell.execute_reply.started":"2025-05-25T00:09:10.400388Z","shell.execute_reply":"2025-05-25T00:09:10.445284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize=(6,4)\nplot_(df=added_by_year,\n          x='year_added',\n          y='count',\n          x_label='Year added',\n          y_label='count',\n          title=f\"New songs adding rate by year\\n Total ={added_by_year['count'].sum()} \",\n          inverted=False\n         )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.447353Z","iopub.execute_input":"2025-05-25T00:09:10.44758Z","iopub.status.idle":"2025-05-25T00:09:10.78345Z","shell.execute_reply.started":"2025-05-25T00:09:10.447562Z","shell.execute_reply":"2025-05-25T00:09:10.782539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Song Adding Habits**\n\n- 📈 **Peak Curation Year**: **2022** saw the most song additions (**795 tracks**) — over **26%** of all liked songs added during the entire period.\n\n- 📉 **Sharp Decline in 2025**: Only **72 songs added** in 2025 (partial year), suggesting a slowdown in music discovery or playlist curation.\n\n- 🌟 **High Activity in 2020–2022**: Over **1,800 songs** added during these three years — aligns with high listening hours, especially in 2020 and 2024.\n\n- 🧩 **2019 as Starting Point**: Only **275 songs added** in 2019 — possibly reflecting early-stage playlist building or limited data.\n\n- 🎯 **Total Liked Songs Added**: **3,065 unique tracks** liked and saved over time — indicating active engagement with discovered music.\n\n  ---","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.2 Yearly Added Tracks Analysis**\n\nIn this part, we analyze the number of tracks added each month for each year from 2018 to 2025. The code generates a list of DataFrames, each representing the monthly distribution of added tracks for a specific year.\n\n##### **Key Components**\n\n1. **`yearly_plots`**: A list that will store the DataFrames for each year.\n2. **`month_dict_inverted`**: A dictionary mapping month names to their corresponding numerical values.\n3. **`get_yearly_added_df` Function**:\n   - **Parameters**:\n     - `year`: The specific year to filter the data.\n     - `df`: The DataFrame containing the track data.\n   - **Process**:\n     - Filters the DataFrame to include only rows where `year_added` matches the specified year.\n     - Groups the filtered data by `month_added`.\n     - Aggregates the data to count the number of tracks added each month.\n     - Resets the index and renames the count column for clarity.\n     - Sorts the resulting DataFrame by the count in descending order.\n4. **Loop**:\n   - Iterates over the years from 2018 to 2025.\n   - Calls `get_yearly_added_df` for each year and appends the result to `yearly_plots`.\n","metadata":{}},{"cell_type":"code","source":"yearly_plots = []\nmonth_dict_inverted = {\n    # Month names to numbers\n    \"January\": 1,\n    \"February\": 2,\n    \"March\": 3,\n    \"April\": 4,\n    \"May\": 5,\n    \"June\": 6,\n    \"July\": 7,\n    \"August\": 8,\n    \"September\": 9,\n    \"October\": 10,\n    \"November\": 11,\n    \"December\": 12}\n\n\ndef get_yearly_added_df(year,df):\n    \n    condition = (df['year_added'] == year)\n    return df[condition]\\\n        .groupby('month_added')\\\n        .agg({'ts':'count','year_added':'first'})\\\n        .reset_index()\\\n        .rename({'ts':'count'},axis=1)\\\n        .sort_values('count',ascending=False)\n\nfor i in range(2018,2026):\n    yearly_plots.append(get_yearly_added_df(i,unique_track_names))\n\nfor df in yearly_plots:\n    display(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.784535Z","iopub.execute_input":"2025-05-25T00:09:10.784842Z","iopub.status.idle":"2025-05-25T00:09:10.864374Z","shell.execute_reply.started":"2025-05-25T00:09:10.784811Z","shell.execute_reply":"2025-05-25T00:09:10.863441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"default_figsize=(10,4)\nyear=2018\nfor yearly_plot in yearly_plots:\n    yearly_plot['month_added_n']=yearly_plot['month_added'].map(month_dict_inverted)\n    yearly_plot = yearly_plot.sort_values('month_added_n')\n    \n    plot_(df=yearly_plot,\n              x='month_added',\n              y='count',\n              x_label='Month Added',\n              y_label='count',\n              title=f\"New songs adding rate by Month for the year {year}\\nTotal for this year: {yearly_plot['count'].sum()}\",\n              inverted=False\n             )\n    year +=1\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.865389Z","iopub.execute_input":"2025-05-25T00:09:10.865692Z","iopub.status.idle":"2025-05-25T00:09:10.895691Z","shell.execute_reply.started":"2025-05-25T00:09:10.865663Z","shell.execute_reply":"2025-05-25T00:09:10.894485Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Yearly Added Tracks Analysis**\n\n##### 📈 **General Trends**\n- **2022** was the most active year for adding new songs (**795 tracks**) — with **February (147)** and **March (137)** as peak months.\n- **2025** shows a sharp decline — only **72 tracks added**, with most activity in **January (43)**.\n\n##### 🔝 **Peak Months for Music Curation**\n- **Top Add Month**: **September 2020** with **140 additions**.\n- Multiple years show spikes in:\n  - **February**\n  - **September**\n  - **October**\n  These could align with seasonal mood shifts, playlist refreshes, or music discovery habits.\n\n##### 🧠 **Year-by-Year Highlights**\n\n- **2018**: No data available — likely due to limited tracking or early Spotify usage.\n- **2019**: Started building the library — **October (106)** led by a wide margin.\n- **2020**: High curation during **July (106)** and **September (140)** — consistent with increased listening during lockdowns.\n- **2021**: More balanced throughout the year — **December (68)** and **November (60)** stood out.\n- **2022**: Most prolific year — **February and March** were especially active.\n- **2023**: Strong start with **February (127)** and **March (100)** — then declined toward year-end.\n- **2024**: Activity dropped significantly — **November (39)** and **August (36)** were top months.\n- **2025**: Very low overall — suggests reduced engagement or a pause in active curation.\n\n\n##### 🔄 **Behavioral Observations**\n- **Spikes often occur in fall months** (September–November), possibly linked to mood-based playlisting or seasonal affective listening.\n- **February** appears frequently as a high-add month — could indicate a reset or refresh period in my music habits.\n- **Decline from 2022 onward** may reflect playlist saturation, lifestyle changes, or less time spent curating.\n---","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.2 Display Count of Added Songs by Genre for a Specific Year**\n\nThis part of our analysis is aimed to analyze the number of unique tracks added in a specific year (2022) and categorize them by genre. It provides a clear breakdown of the most popular genres based on the number of new tracks added.\n\n##### **Key Components**\n\n1. **`condition`**:\n   - Filters the DataFrame `df_merged` to include only rows where `year_added` is 2022.\n\n2. **`df_unique_tracks`**:\n   - Groups the filtered DataFrame by `master_metadata_track_name` and selects the first occurrence of each track to ensure uniqueness.\n   - Resets the index to create a clean DataFrame.\n\n3. **`added_tracks_genres`**:\n   - Groups the unique tracks by `Genres`.\n   - Aggregates the data to count the number of unique tracks in each genre.\n   - Sorts the resulting DataFrame by the count in descending order.\n   - Renames the count column to `n_new_tracks` for clarity.\n\n4. **Output**:\n   - Prints the shape of the resulting DataFrame.\n   - Displays the DataFrame with the top 20 genres by the number of new tracks added.\n","metadata":{}},{"cell_type":"code","source":"#display count of added songs by genre for specefic year\n\ncondition = (df_merged['year_added'] == 2022) \n\ndf_unique_tracks = df_merged[condition].groupby(['master_metadata_track_name']).first().reset_index()\n\n\nadded_tracks_genres = df_unique_tracks.groupby(['Genres'])\\\n        .agg({'master_metadata_track_name':'count'})\\\n        .sort_values('master_metadata_track_name',ascending=False)\\\n        .reset_index()\\\n        .rename({'master_metadata_track_name':'n_new_tracks'},axis=1)\n\nprint(added_tracks_genres.shape)\nadded_tracks_genres\n\nadded_tracks_genres.head(20)","metadata":{"jupyter":{"source_hidden":true},"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.896279Z","iopub.status.idle":"2025-05-25T00:09:10.896592Z","shell.execute_reply.started":"2025-05-25T00:09:10.896464Z","shell.execute_reply":"2025-05-25T00:09:10.896476Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 Key Insights: Added Songs by Genre in 2022\n\n- 🎵 **Most Added Genre**: **Polka** stands out with **26 new tracks added**, reflecting either a deepening interest or nostalgic influence.\n\n- 🧩 **Genre Diversity**: A total of **282 unique genres** appear, showing broad exploration across styles — from classical to niche global and subcultural genres.\n\n- 📊 **Top Non-Polka Genres**:\n  - **Chamber pop, baroque pop (13)**\n  - **Gangster rap, west coast hip hop (13)**\n  - **Slowcore, singer-songwriter (13)**\n  - Reflects a blend of emotional, atmospheric, and lyrical music preferences.\n\n- 🎼 **Classical Influence Continues**:\n  - Multiple entries related to **classical, chamber, and orchestral music** show continued curation within this domain.\n  - Classical-related genres contributed **~12–7 tracks each**, reinforcing it as a core listening area.\n\n- 🌍 **Global & Niche Appeal**:\n  - Presence of **Afropop, Gnawa, Celtic rock, Tango**, and **Latin Hip Hop** indicates openness to international and traditional sounds.\n  - Suggests intentional discovery or playlist expansion beyond mainstream genres.\n  ---","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.3 Analysis of New Song Additions by Month**\n\nThis code snippet consolidates data from multiple years to analyze the number of new songs added each month. It provides insights into the distribution of new song additions over time, including the total number of months, maximum and minimum songs added in a month, mean, and standard deviation.\n\n##### Key Components\n\n1. **`all_months_new_added`**:\n   - Concatenates all DataFrames in `yearly_plots` into a single DataFrame.\n   - Resets the index to create a new column `month_number` representing the absolute month number.\n   - Sorts the DataFrame by the count of new songs added in descending order.\n\n2. **Summary Statistics**:\n   - Total number of months.\n   - Maximum number of songs added in a single month.\n   - Minimum number of songs added in a single month.\n   - Mean number of songs added per month.\n   - Standard deviation of the number of songs added per month.\n\n3. **Output**:\n   - Prints summary statistics.\n   - Displays the top 10 months with the highest number of new songs added.\n   - Displays the bottom 10 months with the lowest number of new songs added.\n","metadata":{}},{"cell_type":"code","source":"# adding new song rate by months with absolute month number\n\nall_months_new_added = pd.concat(yearly_plots)\nall_months_new_added=all_months_new_added.reset_index(drop=True).reset_index().rename({'index':'month_number'},axis=1).sort_values('count',ascending=False)\nprint(f\"Total number of months :{all_months_new_added.month_number.max()}\")\nprint(f\"Max songs/month :{all_months_new_added['count'].max()}\")\nprint(f\"Min songs/month :{all_months_new_added['count'].min()}\")\nprint(f\"mean songs/month :{all_months_new_added['count'].mean()}\")\nprint(f\"std songs/month :{all_months_new_added['count'].std()}\")\ndisplay(all_months_new_added.sort_values('month_number').head(60))\ndisplay(all_months_new_added.sort_values('month_number').tail(8))\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.897681Z","iopub.status.idle":"2025-05-25T00:09:10.89794Z","shell.execute_reply.started":"2025-05-25T00:09:10.89782Z","shell.execute_reply":"2025-05-25T00:09:10.897831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt_months(all_months_new_added,'Songs Added per Month Over Time')","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.899519Z","iopub.status.idle":"2025-05-25T00:09:10.899785Z","shell.execute_reply.started":"2025-05-25T00:09:10.899666Z","shell.execute_reply":"2025-05-25T00:09:10.899677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: New Song Additions by Month**\n\n##### 📊 **Summary Statistics**\n- **Total months tracked**: 67\n- **Max songs added in a month**: **147 (Feb 2022)**\n- **Min songs added in a month**: **2 (July 2021)**\n- **Average per month**: ~**45 songs**\n- **Standard deviation**: ~**37** — indicating high variability in monthly adding behavior\n\n---\n\n##### 🥇 **Top Months for Adding New Songs**\n| Rank | Month       | Year | Count |\n|------|-------------|------|-------|\n| 1    | February    | 2022 | 147   |\n| 2    | September   | 2020 | 140   |\n| 3    | March       | 2022 | 137   |\n| 4    | October     | 2019 | 106   |\n| 5    | July        | 2020 | 106   |\n\n- **February and September** appear frequently among top months — possibly tied to mood shifts, seasonal playlist updates, or intentional discovery phases.\n\n---\n\n##### 🥉 **Bottom Months for Adding New Songs**\n| Rank | Month   | Year | Count |\n|------|---------|------|-------|\n| 1    | July    | 2021 | 2     |\n| 2    | April   | 2020 | 7     |\n| 3    | April   | 2022 | 44    |\n| 4    | May     | 2020 | 3     |\n| 5    | August  | 2021 | 4     |\n\n- Some months had very low activity — could reflect:\n  - Reduced music discovery\n  - Playlist saturation\n  - Data gaps or reduced app usage\n\n---\n\n##### 📅 **Behavioral Patterns**\n- **High Engagement Periods**:\n  - **Early 2020**, **early 2022**, and **early 2023** all saw intense curation spikes — possibly linked to increased indoor time or emotional reliance on music.\n  \n- **Decline After 2022**:\n  - A steady drop in new additions from mid-2023 onward, with 2025 showing minimal activity.\n\n- **January & February Momentum**:\n  - These months often show strong additions — suggesting possible annual reset habits or goal-driven curation.\n---","metadata":{}},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **6.3 Listening frequency and user engagement analysis**\n\n#### **6.3.1 Top Songs by number of listenings Analysis**\n\n#### **Purpose**\nThis code analyzes user engagement with songs by:\n1. Identifying the most frequently played tracks\n2. Tracking how many unique years each song was played\n3. Calculating total listening time and other engagement metrics\n\n\n#### **Key Metrics Calculated**\n| Metric | Description | Insights Provided |\n|--------|-------------|-------------------|\n| `year_count` | Number of unique years the song was played | Long-term popularity |\n| `n_listennings` | Total play count | Overall popularity |\n| `total_minutes_playback` | Sum of minutes played | Engagement depth |\n| `unique_years` | Array of specific years played | Consistency over time |\n| `timestamp_1/2` | First/last play timestamps | Usage timeline |\n\n#### **Interpretation Guide**\n1. **High `year_count` + High `n_listennings`**: Evergreen favorites\n2. **High `year_count` + Low `n_listennings`**: Consistent but occasional plays\n3. **Low `year_count` + High `n_listennings`**: Recent obsessions\n","metadata":{}},{"cell_type":"code","source":"by_year_count = (\n    df_merged.loc[:,['year','master_metadata_album_artist_name'\n                     ,'master_metadata_track_name','month','day',\n                     'hour','minutes_played','Duration (ms)','ts',\n                     'not_skipped_count']]\n)\nresult_years = by_year_count.groupby(['master_metadata_track_name']).agg(\n    artist_name=('master_metadata_album_artist_name','first'),\n    unique_years=('year', 'unique'),\n    year_count=('year', 'nunique'),\n    total_minutes_playback=('minutes_played','sum'),\n    song_duration=('Duration (ms)','first'),\n    n_listennings=('not_skipped_count','first'),\n    timestamp_1=('ts','min'),\n    timestamp_2=('ts','max')\n).sort_values(['year_count','n_listennings'],ascending=False).reset_index()\nresult_years['song_duration'] = np.round(result_years['song_duration']/(1000*60),2)\nwith pd.option_context('display.max_seq_items', None, 'display.max_colwidth', None):\n    display(result_years.head(10))","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.901196Z","iopub.status.idle":"2025-05-25T00:09:10.901641Z","shell.execute_reply.started":"2025-05-25T00:09:10.901464Z","shell.execute_reply":"2025-05-25T00:09:10.901483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Top Songs by Number of Listenings**\n\nThis analysis identifies the most-played songs based on **how many years they appeared** and **how frequently they were played**, offering a deep look into my long-term musical preferences.\n\n\n##### 🥇 **Top Track**: **\"O surdato 'nnammurato - Live\" by Massimo Ranieri**\n- **Played across 7 years (2019–2025)** — longest consistent play history\n- **Total listening time**: **~4.58 hours**\n- **Play count**: **79 listens**\n- Shows **deep emotional or nostalgic connection**\n\n \n\n##### 📊 **Top 10 Tracks Summary**\n\n| Song Title | Artist | Years Played | Total Minutes | Plays |\n|-----------|--------|--------------|----------------|-------|\n| O surdato 'nnammurato - Live | Massimo Ranieri | 7 | 274.7 | 79 |\n| Reginella - Live | Massimo Ranieri | 7 | 270.2 | 74 |\n| John Wayne Gacy, Jr. | Sufjan Stevens | 7 | 200.3 | 65 |\n| Buckets Of Rain | Ragga Gröndal | 7 | 138.4 | 58 |\n| Emmylou | First Aid Kit | 7 | 319.9 | 48 |\n| Svo Hljótt | Sigur Rós | 7 | 279.1 | 47 |\n| Goat | French For Rabbits | 7 | 118.7 | 46 |\n| Alfonsina Y El Mar | Mercedes Sosa | 7 | 150.9 | 42 |\n| Dduje pravise - Live | Massimo Ranieri | 7 | 88.98 | 41 |\n| Ágætis byrjun | Sigur Rós | 7 | 229.6 | 36 |\n\n \n\n##### 🎵 **Genre & Artist Highlights**\n\n- 🧩 **Genre Blend**: Includes **Neapolitan folk, indie folk, ambient, classical, and Latin American music** — reflecting a diverse and emotionally rich taste.\n- 🇮🇹🎵 **Massimo Ranieri Dominance**: 3 tracks in top 10 — indicating strong cultural or emotional resonance with Italian/Live performances.\n- 🌿 **Sufjan Stevens & Sigur Rós**: Appear multiple times — pointing to appreciation for **emotive, atmospheric, and introspective music**.\n- 🌍 **Global Influence**: Presence of **Mercedes Sosa (Argentina)** and **French For Rabbits (NZ)** shows openness to global music culture.\n\n \n\n##### 📅 **Longevity of Engagement**\n\n- 📆 **All Top 10 songs played across 7 years** — showing **exceptional staying power** and consistent emotional or functional value.\n- This suggests these are not just favorites, but **revisited regularly** over time — possibly linked to specific moods, memories, or routines.\n\n \n\n##### 💡 **Practical Takeaways**\n\n- 🎶 **Evergreen Favorites**: These tracks can be used as anchors for **mood-based playlists** or **long-term engagement metrics**.\n- 🧠 **Emotional Triggers**: Consider exploring what events or feelings are associated with repeated plays of these songs.\n- 📈 **Content Strategy**: If I create playlists or curate content, these songs represent **strong core elements** that listeners return to.\n----","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.2 Daily Song Engagement Analysis**\n\n##### **Purpose**\nThis code analyzes song popularity by:\n1. Tracking how many unique days each song was played\n2. Calculating total listening time per track\n3. Identifying temporal patterns of song engagement\n\n\n##### **Key Metrics Calculated**\n| Column | Description | Analytical Value |\n|--------|-------------|------------------|\n| `day_count` | Number of unique days played | Measures song's temporal reach |\n| `unique_days` | Specific day IDs when played | Identifies play patterns/clusters |\n| `total_minutes_playback` | Sum of all listening minutes | Measures engagement depth |\n| `song_duration` | Track length in minutes | Contextualizes play counts |\n| `timestamp_1/2` | First/last play timestamps | Shows longevity of engagement |\n\n##### **Interpretation Guide**\n1. **High `day_count` + High `total_minutes`**  \n   - Frequently played favorites (e.g., daily commute songs)\n   \n2. **High `day_count` + Low `total_minutes`**  \n   - Short tracks played regularly (e.g., alarm tones)\n   \n3. **Low `day_count` + High `total_minutes`**  \n   - Session-based listening (e.g., album deep-dives)\n\n","metadata":{}},{"cell_type":"code","source":" \nby_day_count = df_merged.loc[:,['day_sequential_n','master_metadata_track_name','year','month','day','hour','minutes_played','Duration (ms)','ts']]\nresult = by_day_count.groupby(['master_metadata_track_name']).agg(\n    unique_days=('day_sequential_n', 'unique'),\n    day_count=('day_sequential_n', 'nunique'),\n    total_minutes_playback=('minutes_played','sum'),\n    song_duration=('Duration (ms)','first'),\n    timestamp_1=('ts','min'),\n    timestamp_2=('ts','max')\n).sort_values(['day_count','total_minutes_playback'],ascending=False).reset_index()\nresult['song_duration'] = result['song_duration']/(1000*60)\nunique_days_by_song = result.copy()\nwith pd.option_context('display.max_seq_items', None, 'display.max_colwidth', None):\n    display(result.head(30))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.903064Z","iopub.status.idle":"2025-05-25T00:09:10.903359Z","shell.execute_reply.started":"2025-05-25T00:09:10.903201Z","shell.execute_reply":"2025-05-25T00:09:10.90322Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Daily Song Engagement Analysis**\n\nThis analysis explores how my listening behavior varies across songs, based on **how many unique days** a song was played and the **total minutes spent listening** to it.\n\n---\n\n##### 🥇** Most Engaging Songs (High Day Count + High Listening Time)**\n\n| Song Title | Artist | Days Played | Total Minutes | Notes |\n|-----------|--------|--------------|----------------|-------|\n| **A Meaningful Moment Through a Meaning(less) Process** | — | 67 | 325.94 | Most days played in dataset |\n| **Casimir Pulaski Day** | Sufjan Stevens | 62 | 398.42 | Emotional indie folk staple |\n| **Attrape-rêve** | — | 62 | 380.93 | Newer track with high daily engagement |\n| **Emmylou** | First Aid Kit | 62 | 319.99 | Consistent favorite over years |\n\n- These tracks show **long-term relevance**, appearing frequently across many days.\n- Ideal for playlists targeting **daily listeners** or **mood-based routines**.\n\n \n\n##### 🎵 **Long-Played Favorites (Low Day Count + High Listening Time)**\n\n| Song Title | Artist | Days Played | Total Minutes | Notes |\n|-----------|--------|--------------|----------------|-------|\n| **Piano Concerto No. 5 \"Emperor\"** | Beethoven | 48 | **780.54** (~13 hrs) | Extremely long total playback |\n| **Svo Hljótt** | Sigur Rós | 36 | **279.12** | Deep emotional resonance |\n| **Hey Joe** | — | 35 | **199.11** | Frequent deep sessions |\n\n- These songs were not played every day, but when they were, they had **long listening durations** — suggesting:\n  - Full-album plays\n  - Immersive sessions\n  - Repeated listening during focused time\n\n \n\n##### 🧠 **Longevity of Engagement (Earliest to Latest Plays)**\n\n| Song Title | First Played | Last Played | Span |\n|-----------|--------------|-------------|------|\n| **O surdato 'nnammurato - Live** | Sep 2019 | Feb 2025 | **~5.5 years** |\n| **John Wayne Gacy, Jr.** | Aug 2019 | Jan 2025 | ~5.5 years |\n| **Svo Hljótt** | Oct 2019 | Jan 2025 | ~5.5 years |\n| **Emmylou** | Sep 2019 | Jan 2025 | ~5.5 years |\n\n- These songs have been part of my library for **over 5 years**, showing **lasting emotional or contextual value**.\n\n---\n\n##### 📊 **Behavioral Patterns**\n\n- 📅 **Consistency Over Time**: Some tracks appear **year after year**, indicating enduring appeal.\n- ⏱️ **Session-Based Listening**: Tracks like **Beethoven’s Piano Concerto** suggest Spotify is used for **deep dives into longer works**.\n- 🧩 **Genre Diversity**: Top-played songs span classical, indie folk, ambient, polka, and Latin genres — reflecting a **broad emotional and cultural palette**.\n\n \n\n##### 💡 **Practical Takeaways**\n\n- 🎶 **Playlist Strategy**: Use top daily-played songs as **anchor tracks** in mood or routine-based playlists.\n- 📆 **Engagement Depth**: Analyze why certain tracks are revisited often — could be tied to **emotional triggers, memory cues, or functional use** (e.g., focus, relaxation).\n- 🧠 **Behavioral Insight**: Long-playback songs may indicate **immersive listening moments** — ideal for studying, meditation, or creative work.","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.3 Hourly Song Engagement Analysis**\n \n\n##### **Purpose**\nThis code analyzes song engagement by tracking:\n1. How many unique hourly listening sessions each song appears in\n2. Total listening time per track\n3. Temporal patterns of when songs were played\n\n\n\n##### **Key Metrics Calculated**\n| Metric | Description | Analytical Value |\n|--------|-------------|------------------|\n| `hour_count` | Number of unique hourly sessions | Measures song reach across time |\n| `unique_hours` | Specific hour IDs when played | Identifies temporal patterns |\n| `total_minutes_playback` | Sum of all listening minutes | Measures engagement depth |\n| `song_duration` | Track length in minutes | Context for play counts |\n| `timestamp_1/2` | First/last play timestamps | Shows longevity |\n\n##### **Interpretation Guide**\n1. **High `hour_count` + High `total_minutes`**: Frequently played favorites\n2. **High `hour_count` + Low `total_minutes`**: Background/short tracks\n3. **Low `hour_count` + High `total_minutes`**: Intensive session tracks\n","metadata":{}},{"cell_type":"code","source":"by_hour_count = df_merged.loc[:,['hour_sequential_n','master_metadata_track_name','year','month','day','hour','minutes_played','Duration (ms)','ts']]\nresult_hours = by_hour_count.groupby(['master_metadata_track_name']).agg(\n    unique_hours=('hour_sequential_n', 'unique'),\n    hour_count=('hour_sequential_n', 'nunique'),\n    total_minutes_playback=('minutes_played','sum'),\n    song_duration=('Duration (ms)','first'),\n    timestamp_1=('ts','min'),\n    timestamp_2=('ts','max')\n).sort_values(['hour_count','total_minutes_playback'],ascending=False).reset_index()\nresult_hours['song_duration'] = np.round(result_hours['song_duration']/(1000*60),2)\nwith pd.option_context('display.max_seq_items', None, 'display.max_colwidth', None):\n    display(result_hours.head(10))","metadata":{"jupyter":{"source_hidden":true},"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.904147Z","iopub.status.idle":"2025-05-25T00:09:10.904426Z","shell.execute_reply.started":"2025-05-25T00:09:10.904278Z","shell.execute_reply":"2025-05-25T00:09:10.904288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑 **Key Insights: Song Popularity by Unique Listening Hours**\n\nThis analysis identifies the most frequently played songs based on **how many unique hourly listening sessions** they appeared in, along with **total listening time** and **temporal engagement patterns**.\n\n---\n\n##### 🥇 **Most Engaging Songs (High Hour Count + High Playback Time)**\n\n| Song Title | Artist | Unique Hours Played | Total Minutes | Notes |\n|-----------|--------|----------------------|----------------|-------|\n| **Attrape-rêve** | — | **97** | 380.93 | **Most sessioned song**\n| **Casimir Pulaski Day** | Sufjan Stevens | 74 | 398.42 | Emotional indie folk favorite\n| **A Meaningful Moment Through a Meaning(less) Process** | — | 75 | 325.94 | Long-term background staple\n| **Emmylou** | First Aid Kit | 80 | 319.99 | Consistently revisited over years\n\n- These tracks were played across **many distinct hours**, indicating frequent inclusion in **daily routines, moods, or ambient listening sessions**.\n- Ideal for playlists designed to accompany **work, study, or relaxation**.\n\n---\n\n##### **🎵 Session-Based Favorites (Low Hour Count + High Playback Time)**\n\n| Song Title | Artist | Unique Hours | Total Minutes | Notes |\n|-----------|--------|--------------|----------------|-------|\n| **Piano Concerto No. 5 \"Emperor\" – Beethoven** | — | **61** | **780.54 (~13 hrs)** | Extremely long plays\n| **Graf-Zeppelin-Marsch** | — | 75 | 232.66 | Polka classic with high reach\n\n- Tracks like **Beethoven’s Piano Concerto** were not played every day, but when they were, **each session was long and immersive**.\n- Suggests use during focused moments like **deep work, meditation, or full-album listening sessions**.\n\n---\n\n##### 🧠 **Long-Term Favorites (Earliest to Latest Plays)**\n\n| Song Title | First Played | Last Played | Span |\n|-----------|--------------|-------------|------|\n| **O surdato 'nnammurato - Live** | Sep 2019 | Feb 2025 | ~5.5 years |\n| **Reginella - Live** | Oct 2019 | Feb 2025 | ~5.5 years |\n| **Death with Dignity** | Aug 2019 | Aug 2024 | ~5 years |\n\n- These songs have been part of my listening habits for **years**, showing **long-term emotional or contextual relevance**.\n\n---\n\n##### **📊 Behavioral Patterns**\n\n- 🕐 **Session-Based Listening**: Some songs appear in many distinct hourly sessions, suggesting Spotify is used as a **companion throughout the day**.\n- ⏱️ **Long Tracks Matter**: The presence of long classical pieces shows that I engage deeply with **extended works**, especially for **immersive experiences**.\n- 🧩 **Genre Diversity**: Top-played songs span classical, indie folk, polka, ambient, and Latin genres — reflecting a **broad emotional and cultural palette**.\n\n---\n\n##### 💡 **Practical Takeaways**\n\n- 🎶 **Playlist Strategy**: Use top hourly-played songs as **anchor tracks** in mood or routine-based playlists.\n- 📆 **Engagement Depth**: Analyze why certain tracks are revisited often — could be tied to **emotional triggers, memory cues, or functional use** (e.g., focus, relaxation).\n- 🧠 **Behavioral Insight**: Long-playback songs may indicate **deep listening sessions** — ideal for studying, meditation, or creative work.\n","metadata":{}},{"cell_type":"markdown","source":"#### **6.3.4 Peak Hour Analysis for Top Songs**\n\n##### **Purpose**\nThis code analyzes the **most active hours of the day** for the top 3 songs during their **peak engagement days**.\n\n##### **Output Interpretation**\nFor each song, you'll see:\n1. **Top 3 days** with most hourly play sessions\n2. **First timestamp** of each day\n3. **Number of unique hours** the song was played\n4. **Specific hours** (0-23) when plays occurred\n","metadata":{}},{"cell_type":"code","source":"songs = ['Attrape-rêve','Emmylou','Casimir Pulaski Day']\nfor song in songs:\n    condition = df_merged['Track Name'] == song\n    display(song,(\n        df_merged[condition].groupby('day_sequential_n')\n        .agg(year=('year','first'),month=('month','first')\n            ,day=('day','first'),count=('ts','count'),\n             unique_hours_of_the_day=('hour','unique'),\n            minutes_playback=('minutes_played','sum'),\n            song_duration=('Duration_minutes','first'),\n             nhours=('hour','nunique')\n            )\n        .sort_values('nhours',ascending=False)\n        .head(3).reset_index()\n    ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:09:10.905511Z","iopub.status.idle":"2025-05-25T00:09:10.905774Z","shell.execute_reply.started":"2025-05-25T00:09:10.905651Z","shell.execute_reply":"2025-05-25T00:09:10.905665Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### 🔑**Key Insights: Peak Hour Analysis for Top Songs**\n\nThis analysis identifies the **top engagement days** and **peak listening hours** for my top 3 songs:  \n- **Attrape-rêve**  \n- **Emmylou**  \n- **Casimir Pulaski Day**\n\n\n##### 🎵 **1. Attrape-rêve**\n- **Most Active Day**: Feb 22, 2024 (**5 unique hours played**) — suggesting a full-day companion track.\n- **Peak Hours**: **10, 17, 18, 20, 22**\n- **Daily Behavior**:\n  - Played across **morning (10), afternoon (13, 16), evening (18), and night (22)** — indicating it's used in multiple contexts.\n  - Notably, played at **10 AM** and **8 PM**, possibly linked to **routine transitions** or **mood-based listening**.\n\n\n##### 🎵 **2. Emmylou**\n- **Most Active Day**: Oct 19, 2019 (**4 unique hours played**) — most spread out usage of the three.\n- **Peak Hours**: **13, 17, 18, 22**\n- **Daily Behavior**:\n  - Played during **midday (13), late afternoon (17), evening (18), and night (22)** — aligning with emotional or ambient use.\n  - Appears frequently at **night (22)** across multiple days.\n\n\n##### 🎵 **3. Casimir Pulaski Day**\n- **Most Active Days**: Multiple days with **2 unique hours played** — less frequent but consistent timing.\n- **Peak Hours**: **0, 10, 18, 19**\n- **Daily Behavior**:\n  - Played at **midnight (0)** and **evening (18–19)** — suggesting either emotional deep-listening or nighttime reflection.\n  - Also appears at **10 AM**, showing versatility across time-of-day.\n\n\n##### 🕐 General Observations\n\n- 🧠 **Evening Dominance**: For all three songs, **18–22 (6 PM – 10 PM)** appear as common peak hours — likely tied to relaxation, mood-setting, or background listening.\n- 🌅 **Morning Appearances**: Tracks like **Attrape-rêve** and **Emmylou** are also present in **morning/afternoon**, suggesting use in daily routines.\n- 🌙 **Night Listening**: The presence of plays at **midnight (0)** suggests these tracks accompany **late-night moods**, **emotional states**, or **insomnia moments**.\n\n","metadata":{}},{"cell_type":"markdown","source":"## **7. Conclusion**\nDrawing upon the analyses performed on my Spotify listening history data from 2018-2025, we can synthesize the key insights, connect findings across different analyses, draw general conclusions about my listening habits, and propose further questions and hypotheses for deeper exploration.\n\n#### **7.1 Summary of Key Insights**\n\nThe exploratory data analysis (EDA) covered various aspects of my Spotify usage, including listening time trends, artist and genre preferences, and song curation habits.\n\n*   **Overall Listening Trends:** I have a substantial listening history with 68,731 initial listening records, spanning 2018-2025. After cleaning, focusing on plays >= 30 seconds and resolving playback anomalies, the dataset contains 33,255 entries.\n*   **Annual Listening:** **2020 was my most active listening year**, with 368.7 hours played, potentially linked to global events leading to more time at home. Listening dropped sharply in 2025, which could indicate reduced music usage, a busier lifestyle, or possibly incomplete data.\n*   **Monthly Listening:** Aggregating across all years, **August is consistently a top listening month**, followed by October and September. There's a noticeable drop in activity during April and May. Looking specifically at 2020, July was the peak month with 66.8 hours, and late summer to fall (August–November) was the most active period.\n*   **Weekly Listening:** The analysis reveals the total hours played on each day of the week, showing variations.\n*   **Hourly Listening:** **12 PM (noon) is my most frequent listening hour**, potentially for lunch breaks or midday sessions. High engagement windows are from 11 AM–1 PM and 5 PM–10 PM, aligning with late morning, early afternoon, and evening use. Listening drops significantly after midnight, with the fewest plays from 4 AM–5 AM. A morning surge starts from 7 AM, peaking around 10 AM.\n*   **Top Genres:** my taste is **diverse, spanning classical, rock, folk, pop, and regional styles**. **\"Post-rock, dream pop\" is the top genre by listening time** (37.67 hours), followed surprisingly by Polka (29.8 hours). Multiple classical subgenres also rank highly.\n*   **Top Artists by Playback Hours:** Classical artists **Beethoven, Sigur Rós, and Mozart** lead by total hours played, often associated with longer song durations. Sigur Rós ranks #2 overall (45.13 hours), reinforcing their appeal for extended listening.\n*   **Top Artists by Play Count:** Focusing on frequency rather than duration, **Classical composers Ludwig van Beethoven and Johann Sebastian Bach rank highest by play count**, followed by Sufjan Stevens and Atahualpa Yupanqui. Sigur Rós is still in the top 10 by count. This view shows a broader mix of classical, folk, and international artists.\n*   **Song Adding Habits:** You've added a total of 3065 unique songs to my library between 2019 and 2025. **2022 was the peak year for adding new songs** (795 tracks), accounting for over 26% of all liked songs. There's a steady drop in new additions from mid-2023 onward, with minimal activity in 2025.\n*   **Yearly Added Tracks:** Analyzing month-by-month additions for each year, **February, September, and October often show spikes** in new song curation across multiple years. September 2020 had the highest monthly additions (140 tracks).\n*   **Added Songs by Genre (2022):** In my most active year for adding, **Polka was the most added genre** (26 tracks), followed by chamber pop/baroque pop, gangster rap/west coast hip hop, and slowcore/singer-songwriter (13 each). The year shows a high genre diversity (282 unique genres) in new additions.\n*   **New Song Additions by Month (Overall):** Across all years, monthly additions show high variability (std dev ~37). Early 2020, 2022, and 2023 saw intense curation spikes, while a decline is noted after 2022.\n*   **Daily Song Engagement:** **\"A Meaningful Moment Through a Meaning(less) Process\"** and **\"Casimir Pulaski Day\"** were played on the most unique days (67 and 62 days respectively), indicating frequent revisits. These are often accompanied by high total listening minutes, suggesting they are \"frequently played favorites\".\n*   **Hourly Song Engagement:** **\"Attrape-rêve\"** and **\"Casimir Pulaski Day\"** appeared in the most unique hourly sessions (97 and 95 unique hours respectively). High hourly counts with high total minutes again point to frequently played favorites, potentially integrated into daily or hourly routines.\n*   **Peak Hour Analysis for Top Songs:** Top engagement days for \"Attrape-rêve\" show plays spread across several hours (e.g., 10 AM, 5-8 PM, 10 PM). \"Emmylou\" and \"Casimir Pulaski Day\" show plays concentrated in fewer, distinct hours per day (e.g., 10 AM, 6 PM, 10 PM, 11 PM). This suggests some songs are integrated into broader daily listening, while others are tied to more specific times or shorter sessions.\n\n#### **7.2 Relating and Connecting the Insights**\n\nSeveral patterns emerge when connecting findings across analyses:\n\n1.  **The 2020 Peak:** The peak in total listening hours in 2020 is consistent with the peak months for *listening* within that year (July, November, September). While 2020 wasn't the peak year for *adding* new songs (that was 2022), it still saw high curation activity in certain months (July, September), aligning with periods of high listening. The top daily listening days also reinforce the dominance of July and September 2020. This suggests 2020 was a period of both intense listening *and* active discovery/curation, possibly driven by external circumstances like lockdowns.\n2.  **The 2025 Decline:** The sharp drop in total listening hours in 2025 mirrors the minimal activity in song additions for the same year. This dual decline suggests a significant shift in overall Spotify engagement, impacting both listening volume and the habit of curating new music.\n3.  **Artist/Genre Dominance:** The top genres by hours (Post-rock/Dream Pop, Classical) are directly linked to the top artists by hours (Sigur Rós, Beethoven, Mozart). The deep dive into \"post-rock, dream pop\" confirms **Sigur Rós's overwhelming dominance within that genre**, accounting for almost all playback time. Comparing hours played vs. play count reveals that artists with longer average track lengths (like Classical composers and Sigur Rós) rank higher by hours, while artists with shorter, frequently revisited songs (like certain folk or traditional artists) rank higher by count. This highlights different modes of engagement – long, immersive sessions vs. shorter, repeated plays.\n4.  **Song Longevity and Engagement:** The analysis of songs played across multiple years identifies \"evergreen favorites\" with consistent play history. \"O surdato ’nnammurato - Live\" by Massimo Ranieri, played across 7 years, aligns with Massimo Ranieri's presence in the top artists by count, suggesting deep, long-term engagement with certain tracks. Tracks like \"A Meaningful Moment Through a Meaning(less) Process\" and \"Casimir Pulaski Day\" appearing on the most unique days and hours further emphasize that certain songs are not just listened to for extended periods (hours), but are also integrated into daily and hourly routines over time.\n5.  **Adding vs. Listening:** While 2022 was the peak year for *adding* songs, it was the *third* most active year for *listening*. This suggests that the period of peak music discovery and curation (2022) might not perfectly align with the period of peak overall listening volume (2020). The high number of genres added in 2022 compared to the top genres by listening hours (dominated by Post-rock/Dream Pop and Classical) indicates that my curation habits explore a wider range of genres than what I spend the most time listening to.\n6.  **Seasonal and Temporal Patterns:** Consistently high listening in late summer/fall months (August-November) across years and peak listening hours (11 AM-1 PM, 5 PM-10 PM) suggest predictable engagement windows. These patterns could be tied to lifestyle, work, or seasonal moods. The spikes in song additions in February, September, and October could align with seasonal mood shifts or periods of active playlist curation.\n\n#### **7.3 General Conclusions**\n\nBased on these insights, several conclusions about my Spotify listening behavior can be drawn:\n\n*   **Eclectic and Deep Taste:** I possess a diverse musical taste, engaging with genres from classical and post-rock to regional folk and niche styles. Within this diversity, there is also significant depth, with artists like Sigur Rós dominating specific genres and classical composers featuring heavily in both hours and play counts.\n*   **Event-Influenced Engagement:** Major life events or external circumstances (like global events in 2020) appear to significantly impact both listening volume and potentially curation habits.\n*   **Structured Listening Habits:** my listening shows clear patterns based on the time of day (midday, evening peaks), day of the week, and months/seasons (late summer/fall peaks).\n*   **Long-Term Loyalty to Favorites:** I return to certain songs and artists consistently over many years, indicating a deep emotional or habitual connection to them. These evergreen favorites cross genre boundaries.\n*   **Distinct Curation and Listening Behaviors:** The peak period for discovering and adding new music (2022) does not perfectly overlap with the peak period for overall listening (2020). Furthermore, my curation explores a wider array of genres than my consistent, high-volume listening.\n*   **Potential for Lifestyle Correlation:** Many patterns (2020 peak, midday/evening listening, seasonal trends, recent decline) strongly suggest that listening behavior is closely tied to my daily routines, work patterns, mood, and overall lifestyle.\n\n#### **7.4 Deeper Questions for Further Analysis and Hypotheses**\n\nThe analysis provides a strong foundation, but also raises intriguing questions for deeper exploration:\n\n1.  **Investigating the 2020 Peak:**\n    *   *Question:* What specific lifestyle changes or events in 2020 correlated with the significant increase in listening and curation?\n    *   *Hypothesis:* The peak in 2020 listening is directly attributable to increased time spent at home during lockdowns or remote work periods. This period also saw higher engagement with atmospheric/focus-oriented genres.\n2.  **Understanding the 2025 Decline:**\n    *   *Question:* Is the sharp drop in listening and additions in 2025 due to a change in music consumption habits (e.g., switching platforms, less free time) or an issue with data capture for that specific year?\n    *   *Hypothesis:* The decline in 2025 reflects a genuine shift in lifestyle leading to less time for music listening and discovery, rather than a data anomaly.\n3.  **Deconstructing Genre Preferences:**\n    *   *Question:* What are the specific characteristics (audio features like energy, valence, tempo) of the top genres and artists by listening hours compared to those highest by play count or curation?\n    *   *Hypothesis:* Genres/artists high in total hours played have specific audio features (e.g., lower energy, higher instrumentalness) that make them suitable for long, background listening sessions, while artists high in play count might have features suited for shorter, repeated plays.\n    *   *Question:* Why does Polka rank so highly in both listening hours and 2022 additions? Is there a specific context or emotional connection to this genre?\n    *   *Hypothesis:* The high ranking of Polka is linked to a specific personal memory, cultural tie, or period of focused interest, distinct from typical music consumption patterns.\n4.  **Connecting Curation and Listening:**\n    *   *Question:* How long, on average, after a song is added to the liked songs library is it first played or frequently listened to?\n    *   *Hypothesis:* There is a significant delay between adding a song and it becoming a \"frequently played favorite,\" indicating a curation process that is separate from immediate listening.\n    *   *Question:* Do the audio features or genres of songs added in peak curation periods (e.g., Feb/Sep/Oct, or 2022) differ from those added in other periods?\n    *   *Hypothesis:* Peak curation periods focus on discovering specific types of music (e.g., more diverse, specific moods) compared to periods of lower activity.\n5.  **Analyzing Temporal Patterns Further:**\n    *   *Question:* How do peak listening hours (11 AM-1 PM, 5 PM-10 PM) vary by weekday vs. weekend?\n    *   *Hypothesis:* Midday peaks are stronger on weekdays (lunch breaks/focus), while evening peaks are more pronounced or shift later on weekends (relaxation/social).\n    *   *Question:* Are the \"evergreen favorite\" songs played consistently across all times of the day/week/year, or are they tied to specific routines or seasons?\n    *   *Hypothesis:* Evergreen favorites are often played during specific, repeated routines (e.g., morning commute, evening winding down) rather than randomly throughout the year.\n6.  **Exploring Behavioral Context:**\n    *   *Question:* Can we correlate listening patterns (especially intense sessions or specific songs) with external factors like weather, mood logs (if available), or calendar events?\n    *   *Hypothesis:* Days with high listening hours or plays of emotionally charged songs are associated with specific moods (e.g., stress, relaxation, nostalgia) or activities (e.g., long work sessions, travel).\n\nBy exploring these questions and testing these hypotheses, we could gain a much deeper understanding of the underlying reasons and contexts driving my unique Spotify listening journey over the years.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}